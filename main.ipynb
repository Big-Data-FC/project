{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wall of imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inline\n",
    "%matplotlib widget\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "RANDOM_SEED = None\n",
    "\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import json\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "from pyspark_dist_explore import hist\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "from pyspark.ml.stat import Summarizer\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "from pyspark.ml.feature import UnivariateFeatureSelector\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import RFE\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "import warnings # supress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/15 14:02:33 WARN Utils: Your hostname, RTX-2070-Rig resolves to a loopback address: 127.0.1.1; using 192.168.1.189 instead (on interface wlp7s0)\n",
      "22/06/15 14:02:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/15 14:02:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = (\n",
    "    SparkConf()\n",
    "    .set(\"spark.ui.port\", \"4050\")\n",
    "    .set(\"spark.executor.memory\", \"4G\")\n",
    "    .set(\"spark.driver.memory\", \"20G\")\n",
    "    .set(\"spark.driver.maxResultSize\", \"10G\")\n",
    ")\n",
    "# .set(\"spark.master\", \"spark://192.168.1.189:4050\")\n",
    "\n",
    "\n",
    "# create the context\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading football players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "modern_df = spark.read.csv(\n",
    "    \"data/players_*.csv\", sep=\",\", inferSchema=True, header=True, multiLine=True\n",
    ")\n",
    "\n",
    "legacy_df = spark.read.csv(\n",
    "    \"data/scraped_players_*.csv\", sep=\",\", inferSchema=True, header=True, \n",
    "    multiLine=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing football players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "leagues = [\n",
    "    \"Spain Primera Division\",\n",
    "    # \"German 1. Bundesliga\",\n",
    "    # \"French Ligue 1\",\n",
    "    # \"English Premier League\",\n",
    "    # \"Italian Serie A\",\n",
    "    # \"Holland Eredivisie\",\n",
    "]\n",
    "\n",
    "# seasons_modern = [\"20\", \"19\", \"18\", \"17\", \"16\", \"15\", \"14\"] \n",
    "seasons_modern = [\"20\", \"19\"] \n",
    "# seasons_legacy = [\"13\", \"12\", \"11\", \"10\", \"09\", \"08\", \"07\"]\n",
    "seasons_legacy = [ ]\n",
    "seasons = seasons_legacy + seasons_modern\n",
    "\n",
    "# football_teams = [\n",
    "#     row[\"club_name\"] for row in modern_df.select(\n",
    "#         \"club_name\"\n",
    "#     ).distinct().collect()\n",
    "# ]\n",
    "\n",
    "macro_roles = [\"0.0\", \"1.0\", \"2.0\", \"3.0\", \"4.0\", \"5.0\", \"6.0\", \"7.0\"]\n",
    "\n",
    "roles_to_macro_roles_dict = {\n",
    "    \"GK\": \"0\",\n",
    "    \"LB\": \"1\",\n",
    "    \"RB\": \"1\",\n",
    "    \"RWB\": \"1\",\n",
    "    \"LWB\": \"1\",\n",
    "    \"CB\": \"2\",\n",
    "    \"CDM\": \"3\",\n",
    "    \"CM\": \"4\",\n",
    "    \"RM\": \"4\",\n",
    "    \"LM\": \"4\",\n",
    "    \"CAM\": \"5\",\n",
    "    \"RW\": \"6\",\n",
    "    \"LW\": \"6\",\n",
    "    \"ST\": \"7\",\n",
    "    \"LF\": \"7\",\n",
    "    \"RF\": \"7\",\n",
    "    \"CF\": \"7\",\n",
    "}\n",
    "NUM_MACRO_ROLES = 8\n",
    "\n",
    "columns = [\n",
    "    \"short_name\",\n",
    "    \"club_name\",\n",
    "    \"league_name\",\n",
    "    \"season\",\n",
    "    \"player_positions\",\n",
    "    \"macro_role\",\n",
    "    \"overall\",\n",
    "    \"value\",\n",
    "    \"pace\",\n",
    "    \"shooting\",\n",
    "    \"passing\",\n",
    "    \"dribbling\",\n",
    "    \"defending\",\n",
    "    \"physic\",\n",
    "    \"attacking_crossing\",\n",
    "    \"attacking_finishing\",\n",
    "    \"attacking_heading_accuracy\",\n",
    "    \"attacking_short_passing\",\n",
    "    \"skill_dribbling\",\n",
    "    \"skill_fk_accuracy\",\n",
    "    \"skill_long_passing\",\n",
    "    \"skill_ball_control\",\n",
    "    \"movement_acceleration\",\n",
    "    \"movement_sprint_speed\",\n",
    "    \"movement_reactions\",\n",
    "    \"power_shot_power\",\n",
    "    \"power_stamina\",\n",
    "    \"power_strength\",\n",
    "    \"power_long_shots\",\n",
    "    \"mentality_aggression\",\n",
    "    \"mentality_penalties\",\n",
    "    \"defending_standing_tackle\"\n",
    "]\n",
    "\n",
    "def get_season(url):\n",
    "    url_split = url.split(\"/\")\n",
    "\n",
    "    # -1 to scale FIFA years down, to have compatibility with all_tables_fixed\n",
    "    return str(\n",
    "        (int(url_split[-2 if url_split[-1] == \"\" else -1][0:2]) - 1)\n",
    "    ).zfill(2)\n",
    "\n",
    "\n",
    "get_season_UDF = udf(lambda url: get_season(url), StringType())\n",
    "\n",
    "roles_to_macro_role_UDF = udf(\n",
    "    lambda roles: float(roles_to_macro_roles_dict[roles.split(\",\")[0]]), StringType()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_modern_df = modern_df.dropDuplicates([\"player_url\"])\n",
    "pre_processed_legacy_df = legacy_df.dropDuplicates([\"player_url\"])\n",
    "\n",
    "pre_processed_modern_df = pre_processed_modern_df.na.fill(0)\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.na.fill(0)\n",
    "\n",
    "pre_processed_modern_df = pre_processed_modern_df.withColumn(\n",
    "    \"season\", get_season_UDF(col(\"player_url\"))\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumn(\n",
    "    \"season\", get_season_UDF(col(\"player_url\"))\n",
    ")\n",
    "\n",
    "pre_processed_modern_df = pre_processed_modern_df.withColumn(\n",
    "    \"macro_role\", roles_to_macro_role_UDF(col(\"player_positions\"))\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumn(\n",
    "    \"macro_role\", roles_to_macro_role_UDF(col(\"player_positions\"))\n",
    ")\n",
    "\n",
    "pre_processed_modern_df = pre_processed_modern_df.withColumnRenamed(\n",
    "    \"value_eur\", \"value\"\n",
    ")\n",
    "\n",
    "pre_processed_modern_df = pre_processed_modern_df.where(\n",
    "    (pre_processed_modern_df.league_name.isin(leagues))\n",
    "    &\n",
    "    (pre_processed_modern_df.season.isin(seasons_modern))\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.where(\n",
    "    (pre_processed_legacy_df.league_name.isin(leagues))\n",
    "    &\n",
    "    (pre_processed_legacy_df.season.isin(seasons_legacy))\n",
    ")\n",
    "\n",
    "pre_processed_modern_df = pre_processed_modern_df.select(columns)\n",
    "\n",
    "# TODO use a for loop\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"pas\", \"passing\"\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"dri\", \"dribbling\"\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.drop(col(\"defending\"))\n",
    "\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"def\", \"defending\"\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"phy\", \"physic\"\n",
    ")\n",
    "\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"sho\", \"shooting\"\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"pac\", \"pace\"\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"bov\", \"overall\"\n",
    ")\n",
    "\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.select(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_df = pre_processed_modern_df.unionByName(\n",
    "    pre_processed_legacy_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building football teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_teams_df = pre_processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAYER_FEATURES = [\n",
    "    \"overall\",\n",
    "    \"value\",\n",
    "    \"pace\",\n",
    "    \"shooting\",\n",
    "    \"passing\",\n",
    "    \"dribbling\",\n",
    "    \"defending\",\n",
    "    \"physic\",\n",
    "    \"attacking_crossing\",\n",
    "    \"attacking_finishing\",\n",
    "    \"attacking_heading_accuracy\",\n",
    "    \"attacking_short_passing\",\n",
    "    \"skill_dribbling\",\n",
    "    \"skill_fk_accuracy\",\n",
    "    \"skill_long_passing\",\n",
    "    \"skill_ball_control\",\n",
    "    \"movement_acceleration\",\n",
    "    \"movement_sprint_speed\",\n",
    "    \"movement_reactions\",\n",
    "    \"power_shot_power\",\n",
    "    \"power_stamina\",\n",
    "    \"power_strength\",\n",
    "    \"power_long_shots\",\n",
    "    \"mentality_aggression\",\n",
    "    \"mentality_penalties\",\n",
    "    \"defending_standing_tackle\"\n",
    "]\n",
    "\n",
    "PLAYER_FEATURES_AVG = [\n",
    "    \"avg(\" + player_feature + \")\" for player_feature in PLAYER_FEATURES\n",
    "]\n",
    "\n",
    "TARGET_VARIABLE = \"points\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_teams_df = football_teams_df.select(\n",
    "    \"season\", \"club_name\", *PLAYER_FEATURES\n",
    ").groupBy(\n",
    "    [\"season\", \"club_name\"]\n",
    ").agg(\n",
    "    { player_feature: \"avg\" for player_feature in PLAYER_FEATURES }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading football teams seasonal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_scores_df = (\n",
    "    spark.read.csv(\n",
    "        \"data/all_tables_fixed_renamed_leagues.csv\",\n",
    "        sep=\",\",\n",
    "        inferSchema=True,\n",
    "        header=True,\n",
    "        multiLine=True,\n",
    "    )\n",
    "    .withColumnRenamed(\"Year\", \"year\")\n",
    "    .withColumnRenamed(\"Team\", \"club_name_abbr\")\n",
    "    .withColumnRenamed(\"P\", \"points\")\n",
    "    .withColumnRenamed(\"Place\", \"place\")\n",
    "    .withColumnRenamed(\"League\", \"league\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing football teams seasonal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_scores_columns = [\n",
    "    \"year\", \"club_name_abbr\", \"points\", \"place\", \"league\"\n",
    "]\n",
    "\n",
    "f = open(\"data/clubs_map.json\")\n",
    "club_name_abbr_to_ext = json.load(f)\n",
    "f.close()\n",
    "\n",
    "abbreviate_season_UDF = udf(\n",
    "    lambda season: str(season)[-2:],\n",
    "    StringType(),\n",
    ")\n",
    "\n",
    "def extend_club_name(club_name_abbr):\n",
    "    try:\n",
    "        return club_name_abbr_to_ext[club_name_abbr]\n",
    "    except KeyError as e:\n",
    "        return \"NOT_FOUND\"\n",
    "    except Exception as e:\n",
    "        return \"GENERAL_EXCEPTION\"\n",
    "\n",
    "extend_club_name_UDF = udf(\n",
    "    lambda club_name_abbr: extend_club_name(str(club_name_abbr)),\n",
    "    StringType(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_seasonal_scores_df = seasonal_scores_df\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.dropDuplicates(\n",
    "    seasonal_scores_columns\n",
    ")\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.na.fill(0)\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.select(\n",
    "    seasonal_scores_columns\n",
    ")\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.withColumn(\n",
    "    \"year\", abbreviate_season_UDF(col(\"year\"))\n",
    ")\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.withColumn(\n",
    "    \"club_name_ext\", extend_club_name_UDF(col(\"club_name_abbr\"))\n",
    ")\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.withColumn(\n",
    "    \"points\", pre_processed_seasonal_scores_df.points.cast(DoubleType())\n",
    ")\n",
    "\n",
    "if pre_processed_seasonal_scores_df.filter(\n",
    "    col(\"club_name_ext\") == \"NOT_FOUND\"\n",
    ").count() > 0:\n",
    "    print(\"WARN: some clubs have NOT been found\")\n",
    "    print(\"Please check your data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.where(\n",
    "    (pre_processed_seasonal_scores_df.year.isin(seasons))\n",
    "    & (pre_processed_seasonal_scores_df.league.isin(leagues))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_scores_pre_join_columns = [\n",
    "    \"year\", \"league\", \"club_name_ext\", \"points\", \"place\"\n",
    "]\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.select(\n",
    "    seasonal_scores_pre_join_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining football teams features with their seasonal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = football_teams_df.join(\n",
    "    pre_processed_seasonal_scores_df,\n",
    "    (football_teams_df.season == pre_processed_seasonal_scores_df.year)\n",
    "    & (\n",
    "        football_teams_df.club_name\n",
    "        == pre_processed_seasonal_scores_df.club_name_ext\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_processed_seasonal_scores_df.select(\"club_name_ext\").distinct().subtract(\n",
    "    df.select(\"club_name_ext\").distinct()\n",
    ").count() > 0:\n",
    "    print(\"WARN: Some football teams have been left out the join (pre_processed_seasonal_scores_df)\")\n",
    "    print(\"Please, check your data!\")\n",
    "\n",
    "if football_teams_df.select(\"club_name\").distinct().subtract(\n",
    "    df.select(\"club_name_ext\").distinct()\n",
    ").count() > 0:\n",
    "    print(\"WARN: Some football teams have been left out the join (football_teams_df)\")\n",
    "    print(\"Please, check your data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1: \"naive\" player features\n",
    "\n",
    "Naive --> simply take the given features and NOT crafting them from other learning processes (i.e. NO clustering or stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_FEATURES = PLAYER_FEATURES_AVG\n",
    "ALL_FEATURES.remove(\"avg(overall)\")\n",
    "ALL_FEATURES.remove(\"avg(value)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=ALL_FEATURES, outputCol=\"all_vec\"\n",
    ")\n",
    "\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_target_relation(\n",
    "    data, x, y, n_rows = 12, n_cols = 2, figsize = (20, 40), color = \"#000000\"\n",
    "):\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "\n",
    "    for x_ind, x_value in enumerate(x):\n",
    "        ax = sns.regplot(\n",
    "            data=pdf,\n",
    "            x=x_value,\n",
    "            y=y,\n",
    "            color = color,\n",
    "            ax=axes[x_ind // n_cols, x_ind % n_cols],\n",
    "        )\n",
    "\n",
    "\n",
    "    fig.tight_layout(pad=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distribution(\n",
    "    data, features, figsize = (20, 40), \n",
    "    color = \"#000000\"\n",
    "):\n",
    "\n",
    "    n_cols = 2\n",
    "    n_rows = int(len(features) / n_cols) if len(features) >= n_cols else n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 30))\n",
    "\n",
    "    for feature_ind, feature in enumerate(features):\n",
    "        _ = sns.histplot(\n",
    "            data[feature],\n",
    "            kde=True,\n",
    "            color=color,\n",
    "            facecolor=color,\n",
    "            ax=axes[feature_ind // n_cols, feature_ind % n_cols],\n",
    "        )\n",
    "\n",
    "    fig.tight_layout(pad=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(\n",
    "    data, features, title = \"Pearson Correlation Matrix\", figsize = (16,12)\n",
    "):\n",
    "\n",
    "    mask = np.zeros_like(data[features].corr(), dtype=bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    with sns.axes_style(\"white\"):  # Temporarily set the background to white\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        plt.title(title, fontsize=24)\n",
    "\n",
    "        cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "        _ = sns.heatmap(\n",
    "            data[features].corr(),\n",
    "            linewidths=0.25,\n",
    "            vmax=0.7,\n",
    "            square=True,\n",
    "            ax=ax,\n",
    "            cmap=cmap,\n",
    "            linecolor=\"w\",\n",
    "            annot=True,\n",
    "            annot_kws={\"size\": 8},\n",
    "            mask=mask,\n",
    "            cbar_kws={\"shrink\": 0.9},\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[explain what does \"raw\" mean]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_RAW = \"#332FD0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-target correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO set an appropriate figsize for Google Colab\n",
    "plot_feature_target_relation(\n",
    "    pdf, ALL_FEATURES, TARGET_VARIABLE, figsize=(4,4), color=COLOR_RAW\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(pdf, ALL_FEATURES, color = COLOR_RAW, figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(pdf, ALL_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have some features with skewed distributions, we'll try to standardize, to see whether it helps with feature skewness or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(\n",
    "    inputCol=\"all_vec\", \n",
    "    outputCol=\"all_vec_std\", \n",
    "    withStd=True, \n",
    "    withMean=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized_df = scaler.fit(standardized_df).transform(standardized_df)\n",
    "df = scaler.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_STD = \"#9254C8\"\n",
    "\n",
    "ALL_FEATURES_STD = [\n",
    "    player_feature + \"_std\" for player_feature in ALL_FEATURES\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = standardized_df.toPandas()\n",
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO make a commodity function, because it will be used in other normalizations as well\n",
    "\n",
    "pdf = pdf.reindex(\n",
    "    columns=list(pdf.columns) + ALL_FEATURES_STD\n",
    ")\n",
    "\n",
    "pdf[ALL_FEATURES_STD] = pdf[\n",
    "    \"all_vec_std\"\n",
    "].transform(\n",
    "    {\n",
    "        ALL_FEATURES_STD[i]: itemgetter(i) for i, p in enumerate(ALL_FEATURES_STD)\n",
    "    }\n",
    "\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-target correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO set an appropriate figsize for Google Colab\n",
    "plot_feature_target_relation(\n",
    "    pdf, ALL_FEATURES_STD, TARGET_VARIABLE, figsize=(4,4), color=COLOR_STD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(\n",
    "    pdf, ALL_FEATURES_STD, color = COLOR_STD, figsize=(10,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[state why pearson correlation matrix does NOT make sense to be plotted again]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_FEATURES_LOG = [\n",
    "    player_feature + \"_log\" for player_feature in ALL_FEATURES\n",
    "]\n",
    "\n",
    "COLOR_LOG = \"#E15FED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_log_UDF = udf(\n",
    "    lambda value: float(np.log2(value)), DoubleType()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, fl in zip(ALL_FEATURES, ALL_FEATURES_LOG):\n",
    "    # log_df = log_df.withColumn(fl, to_log_UDF(col(f)))\n",
    "    df = df.withColumn(fl, to_log_UDF(col(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = log_df.toPandas()\n",
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-target correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO set an appropriate figsize for Google Colab\n",
    "plot_feature_target_relation(\n",
    "    pdf, ALL_FEATURES_LOG, TARGET_VARIABLE, figsize=(4,4), color=COLOR_LOG\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(pdf, ALL_FEATURES_LOG, color = COLOR_LOG, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-max transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_FEATURES_MIN_MAX = [\n",
    "    player_feature + \"_min_max\" for player_feature in ALL_FEATURES\n",
    "]\n",
    "\n",
    "COLOR_MIN_MAX = \"#6EDCD9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(\n",
    "    inputCol=\"all_vec\", \n",
    "    outputCol=\"all_vec_min_max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_df = scaler.fit(min_max_df).transform(min_max_df)\n",
    "df = scaler.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = min_max_df.toPandas()\n",
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO make a commodity function, because it will be used in other normalizations as well\n",
    "\n",
    "pdf = pdf.reindex(\n",
    "    columns=list(pdf.columns) + ALL_FEATURES_MIN_MAX\n",
    ")\n",
    "\n",
    "pdf[ALL_FEATURES_MIN_MAX] = pdf[\n",
    "    \"all_vec_min_max\"\n",
    "].transform(\n",
    "    {\n",
    "        ALL_FEATURES_MIN_MAX[i]: itemgetter(i) for i, p in enumerate(ALL_FEATURES_MIN_MAX)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-target relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO set an appropriate figsize for Google Colab\n",
    "plot_feature_target_relation(\n",
    "    pdf, ALL_FEATURES_MIN_MAX, TARGET_VARIABLE, figsize=(4,4), color=COLOR_MIN_MAX\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(pdf, ALL_FEATURES_MIN_MAX, color = COLOR_MIN_MAX, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO place learning on ## titles here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2: \"less is more\"\n",
    "\n",
    "Ok, considering all features gives trash results.\n",
    "\n",
    "What if we embrace the \"less is more idea\" and try to improve the results by means of using less features?\n",
    "\n",
    "Nevertheless, feature correlation is very high, so, intrinsicly, it already did NOT make much sense to consider them all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA (on min-max normalized data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_df = min_max_df\n",
    "# pca_df = df\n",
    "\n",
    "PCA_NUM_COMPONENTS = 5\n",
    "PCA_NUM_COMPONENTS_TO_PLOT = 2\n",
    "\n",
    "pca = PCA(\n",
    "    k=PCA_NUM_COMPONENTS, \n",
    "    inputCol=\"all_vec_min_max\", \n",
    "    outputCol=\"all_vec_min_max_pcs\"\n",
    ")\n",
    "\n",
    "# pca_model = pca.fit(pca_df)\n",
    "# pca_df = pca_model.transform(pca_df)\n",
    "pca_model = pca.fit(df)\n",
    "df = pca_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "_ = sns.barplot(\n",
    "    x=[i for i in range(PCA_NUM_COMPONENTS_TO_PLOT)],\n",
    "    y=pca_model.explainedVariance.values[0:PCA_NUM_COMPONENTS_TO_PLOT],\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "_ = ax.set_xlabel(\"Eigenvalues\", labelpad=16, fontsize=16)\n",
    "_ = ax.set_ylabel(\"Proportion of Variance\", fontsize=16)\n",
    "_ = ax.set_xticklabels(\n",
    "    [f\"Principal Component {i}\" for i in range(PCA_NUM_COMPONENTS_TO_PLOT)], \n",
    "    rotation=0\n",
    ")\n",
    "_ = ax.set_title(\"Explained variance of each Principal Component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(data, x, y, c, x_label, y_label):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "    _ = plt.scatter(\n",
    "        x = x,\n",
    "        y = y,\n",
    "        c = c,\n",
    "        edgecolor=\"none\",\n",
    "        alpha=1,\n",
    "        cmap=\"rainbow\",\n",
    "        axes=ax\n",
    "    )\n",
    "\n",
    "    _ = ax.set_xlabel(x_label, labelpad=20, fontsize=16)\n",
    "    _ = ax.set_ylabel(y_label, fontsize=16)\n",
    "\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_pdf = pca_df.toPandas()\n",
    "pca_pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(\n",
    "    pca_pdf, \n",
    "    pca_pdf.all_vec_min_max_pcs.map(lambda x: x[0]),\n",
    "    pca_pdf.all_vec_min_max_pcs.map(lambda x: x[1]),\n",
    "    pca_pdf.points,\n",
    "    \"Principal Component 0\",\n",
    "    \"Principal Component 1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO evaluate whether points should be normlized to same scale as PCA values\n",
    "scatter_plot(\n",
    "    pca_pdf, \n",
    "    pca_pdf.all_vec_min_max_pcs.map(lambda x: x[0]),\n",
    "    pca_pdf.points,\n",
    "    pca_pdf.points,\n",
    "    \"Principal Component 0\",\n",
    "    \"Points\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO evaluate whether points should be normlized to same scale as PCA values\n",
    "scatter_plot(\n",
    "    pca_pdf, \n",
    "    pca_pdf.all_vec_min_max_pcs.map(lambda x: x[1]),\n",
    "    pca_pdf.points,\n",
    "    pca_pdf.points,\n",
    "    \"Principal Component 1\",\n",
    "    \"Points\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-target relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[bridge between this and Feature selection]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TNSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log scaling reduces skewedness of \"avg(mentality_penalties)\" feature BUT it increases the skewedness of all the other features.\n",
    "The other scalings (z-score and min-max) do NOT appear to be different than the \"raw\" data distribution.\n",
    "\n",
    "For this reason and due to the limited amount of resources available on Google Colab, we decided to stick with the min-max scaled data.\n",
    "In fact, the min-max scaling places \"for free\" all the features in the same scale, which is a very important consideration for SVM, which will be used in the upcoming sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_selection_df = min_max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = UnivariateFeatureSelector(\n",
    "    featuresCol=\"all_vec\",\n",
    "    labelCol=TARGET_VARIABLE, \n",
    "    selectionMode=\"percentile\"\n",
    ").setFeatureType(\"continuous\").setLabelType(\"categorical\").setSelectionThreshold(0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = dict()\n",
    "\n",
    "# for thr in range(0.1, 1.1, 0.1):\n",
    "# for thr in np.linspace(1, 1, 1):\n",
    "for thr in [0.1]:\n",
    "\n",
    "    selector.setSelectionThreshold(thr)\n",
    "    selector.setOutputCol(\"ufs_\" + str(thr).replace(\".\", \"-\")),\n",
    "    fit_result[str(thr)] = selector.fit(df)\n",
    "    # feature_selection_df = fit_result[str(thr)].transform(\n",
    "    #     feature_selection_df\n",
    "    # )\n",
    "    df = fit_result[str(thr)].transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_selection_pdf = feature_selection_df.toPandas()\n",
    "feature_selection_pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(\n",
    "    feature_selection_pdf,\n",
    "    feature_selection_pdf[\"ufs_0-1\"].map(lambda x: x[0]),\n",
    "    feature_selection_pdf[\"ufs_0-1\"].map(lambda x: x[1]),\n",
    "    feature_selection_pdf.points,\n",
    "    \"Feature 0\",\n",
    "    \"Feature 1\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(\n",
    "    feature_selection_pdf,\n",
    "    feature_selection_pdf[\"ufs_0-1\"].map(lambda x: x[0]),\n",
    "    feature_selection_pdf.points,\n",
    "    feature_selection_pdf.points,\n",
    "    \"Feature 0\",\n",
    "    \"Points\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(\n",
    "    feature_selection_pdf,\n",
    "    feature_selection_pdf[\"ufs_0-1\"].map(lambda x: x[1]),\n",
    "    feature_selection_pdf.points,\n",
    "    feature_selection_pdf.points,\n",
    "    \"Feature 1\",\n",
    "    \"Points\"\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = list(\n",
    "    map(\n",
    "        lambda i: ALL_FEATURES[i], fit_result[\"0.1\"].selectedFeatures\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-target relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO set an appropriate figsize for Google Colab\n",
    "plot_feature_target_relation(\n",
    "    pdf, selected_features, TARGET_VARIABLE, figsize=(4,4), \n",
    "    color=COLOR_MIN_MAX\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at it from the original pearson matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state that these data distribs are trash.\n",
    "\n",
    "So, for this reason, talk about overall and value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall as feature (min-max normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the features are so correlated and performances of attempt 1 are trash, why not considering just the overall as a feature?\n",
    "\n",
    "Maybe, we're lucky and the overall captures some other characteristics thay may steer the prediction a little bit more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERALL = [\"avg(overall)\"]\n",
    "\n",
    "COLOR_OVERALL_MIN_MAX = \"green\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=OVERALL, outputCol=\"overall_vec\"\n",
    ")\n",
    "\n",
    "# min_max_df = assembler.transform(min_max_df)\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERALL_MIN_MAX = [\"avg(overall)_min_max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(\n",
    "    inputCol=\"overall_vec\", \n",
    "    outputCol=\"overall_vec_min_max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_df = scaler.fit(min_max_df).transform(min_max_df)\n",
    "df = scaler.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = min_max_df.toPandas()\n",
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO make a commodity function, because it will be used in other normalizations as well\n",
    "\n",
    "pdf = pdf.reindex(\n",
    "    columns=list(pdf.columns) + OVERALL_MIN_MAX\n",
    ")\n",
    "\n",
    "pdf[OVERALL_MIN_MAX] = pdf[\n",
    "    \"overall_vec_min_max\"\n",
    "].transform(\n",
    "    {\n",
    "        OVERALL_MIN_MAX[i]: itemgetter(i) for i, p in enumerate(OVERALL_MIN_MAX)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-target relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO set an appropriate figsize for Google Colab\n",
    "plot_feature_target_relation(\n",
    "    pdf, OVERALL_MIN_MAX, TARGET_VARIABLE, figsize=(4,4), color=COLOR_OVERALL_MIN_MAX\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look, they are basically the same. In fact, if we check their correlation, we get... [high correlation on pearson]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(pdf, OVERALL_MIN_MAX, color = COLOR_OVERALL_MIN_MAX, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value as feature (min-max normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, we found this paper: \n",
    "\n",
    "So, why not try their approach as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUE = [\"avg(value)\"]\n",
    "\n",
    "COLOR_VALUE_MIN_MAX = \"lime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=VALUE, outputCol=\"value_vec\"\n",
    ")\n",
    "\n",
    "# min_max_df = assembler.transform(min_max_df)\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT BREAKS HERE, if using legacy data as well :C\n",
    "\n",
    "# TODO handle value attribute in legacy datasets\n",
    "# in legacy datasets it's encoded as \"ValueMagnitudeCurrency\" (i.e. 70Mâ‚¬)\n",
    "# gotta convert it to full length, to be compatible with modern (and actually usable!)\n",
    "\n",
    "# df.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUE_MIN_MAX = [\"avg(value)_min_max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(\n",
    "    inputCol=\"value_vec\", \n",
    "    outputCol=\"value_vec_min_max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max_df = scaler.fit(min_max_df).transform(min_max_df)\n",
    "df = scaler.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = min_max_df.toPandas()\n",
    "# NOTE keep the following line disabled!\n",
    "# gotta accumulate overall and value in the same pandas DF, so as we can use it\n",
    "# for the Pearson correlation matrix!\n",
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO make a commodity function, because it will be used in other normalizations as well\n",
    "\n",
    "pdf = pdf.reindex(\n",
    "    columns=list(pdf.columns) + VALUE_MIN_MAX\n",
    ")\n",
    "\n",
    "pdf[VALUE_MIN_MAX] = pdf[\n",
    "    \"value_vec_min_max\"\n",
    "].transform(\n",
    "    {\n",
    "        VALUE_MIN_MAX[i]: itemgetter(i) for i, p in enumerate(VALUE_MIN_MAX)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-target relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO set an appropriate figsize for Google Colab\n",
    "plot_feature_target_relation(\n",
    "    pdf, VALUE_MIN_MAX, TARGET_VARIABLE, figsize=(4,4), color=COLOR_VALUE_MIN_MAX\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(pdf, VALUE_MIN_MAX, color = COLOR_VALUE_MIN_MAX, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint at a very high correlation, then show it with pearson matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df.select(\"overall_vec_min_max\", \"value_vec_min_max\").toPandas()\n",
    "\n",
    "# need to flat every element of the columns, because they are in vectors\n",
    "pdf[\"overall_vec_min_max\"] = pdf[\"overall_vec_min_max\"].map(\n",
    "    lambda x: x[0]\n",
    ")\n",
    "pdf[\"value_vec_min_max\"] = pdf[\"value_vec_min_max\"].map(\n",
    "    lambda x: x[0]\n",
    ")\n",
    "\n",
    "plot_correlation_matrix(\n",
    "    pdf, \n",
    "    [\"overall_vec_min_max\", \"value_vec_min_max\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment this correlation, and move on with life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning for attempt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[\n",
    "    state that via hyperparam grid we'll set the feature column, meaning that we'll try to train the models on all of the attemps\n",
    "\n",
    "[state expected results, according to correlations and similar stuff]\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_selection_learning_df = feature_selection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_selection_train_df, feature_selection_test_df = feature_selection_learning_df.randomSplit(\n",
    "#     # [0.9, 0.1]\n",
    "#     [0.7, 0.3]\n",
    "# )\n",
    "\n",
    "learning_train_df, learning_test_df = df.randomSplit(\n",
    "    # [0.9,0.1]\n",
    "    # NOTE reactive 90/10 split, keep 70/30 just when using one league\n",
    "    [0.7,0.3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS_CV = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_regressor(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    regressor,\n",
    "    regressor_evaluation_metrics,\n",
    "    cv_evaluation_metrics,\n",
    "    hyperparams_grid\n",
    "):\n",
    "\n",
    "    cv_evaluators = {\n",
    "        metric: RegressionEvaluator(\n",
    "            labelCol=\"points\",\n",
    "            metricName=metric,\n",
    "        )\n",
    "        for metric in cv_evaluation_metrics\n",
    "    }\n",
    "\n",
    "    regressor_evaluators = {\n",
    "        metric: RegressionEvaluator(\n",
    "            labelCol=\"points\",\n",
    "            metricName=metric,\n",
    "        )\n",
    "        for metric in regressor_evaluation_metrics\n",
    "    }\n",
    "\n",
    "    cross_validations = {\n",
    "        metric: CrossValidator(\n",
    "            estimator=regressor,\n",
    "            estimatorParamMaps=hyperparams_grid,\n",
    "            evaluator=cv_evaluators[metric],\n",
    "            numFolds=NUM_FOLDS_CV,\n",
    "            collectSubModels=True\n",
    "        )\n",
    "        for metric in cv_evaluation_metrics\n",
    "    }\n",
    "\n",
    "    cross_validated = dict()\n",
    "\n",
    "    for metric in cv_evaluation_metrics:\n",
    "\n",
    "        cross_validated[metric] = cross_validations[\n",
    "            metric\n",
    "        ].fit(train_df)\n",
    "\n",
    "    if (isinstance(regressor, LinearRegression)):\n",
    "        \n",
    "        for metric in cv_evaluation_metrics:\n",
    "\n",
    "            training_result = cross_validated[\n",
    "                metric\n",
    "            ].bestModel.summary\n",
    "\n",
    "            print(\n",
    "                \"***** Evaluating Training Set, (Linear Regression, best model according to metric {}) *****\".format(\n",
    "                    metric\n",
    "                )\n",
    "            )\n",
    "            print(\"RMSE: {:.3f}\".format(training_result.rootMeanSquaredError))\n",
    "            print(\"R2: {:.3f}\".format(training_result.r2))\n",
    "            print(\"Adjusted R2: {:.3f}\".format(training_result.r2adj))\n",
    "            print()\n",
    "\n",
    "        predictions = {\n",
    "            metric: cross_validated[\n",
    "                metric\n",
    "            ].bestModel.transform(test_df)\n",
    "            for metric in cv_evaluation_metrics\n",
    "        }\n",
    "\n",
    "        for m, model in cross_validated.items():\n",
    "\n",
    "                print(\n",
    "                    \"*** {} Set, (rf, best model elected by {}) ***\".format(\n",
    "                        \"Test\", m\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                for e, evaluator in regressor_evaluators.items():\n",
    "\n",
    "                    print(\n",
    "                        \"{}: {}\".format(\n",
    "                            evaluator.getMetricName(), evaluator.evaluate(\n",
    "                                predictions[m]\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                print(\"*******************************\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        for stage_name, stage_df in zip([\"Train\", \"Test\"], [train_df, test_df]):\n",
    "            predictions = {\n",
    "                metric: cross_validated[\n",
    "                    metric\n",
    "                ].bestModel.transform(stage_df)\n",
    "                for metric in cv_evaluation_metrics\n",
    "            }\n",
    "\n",
    "            for m, model in cross_validated.items():\n",
    "\n",
    "                print(\n",
    "                    \"*** {} Set, (rf, best model elected by {}) ***\".format(\n",
    "                        stage_name, m\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                for e, evaluator in regressor_evaluators.items():\n",
    "\n",
    "                    print(\n",
    "                        \"{}: {}\".format(\n",
    "                            evaluator.getMetricName(), evaluator.evaluate(\n",
    "                                predictions[m]\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                print(\"*******************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_classifier(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    classifier,\n",
    "    classifier_evaluation_metrics,\n",
    "    cv_evaluation_metrics,\n",
    "    hyperparams_grid\n",
    "):\n",
    "\n",
    "    cv_evaluators = {\n",
    "        metric: MulticlassClassificationEvaluator(\n",
    "            labelCol=\"macro_place\",\n",
    "            metricName=metric,\n",
    "        )\n",
    "        for metric in cv_evaluation_metrics\n",
    "    }\n",
    "\n",
    "    classifier_evaluators = {\n",
    "        metric: MulticlassClassificationEvaluator(\n",
    "            labelCol=\"macro_place\",\n",
    "            metricName=metric,\n",
    "        )\n",
    "        for metric in classifier_evaluation_metrics\n",
    "    }\n",
    "\n",
    "    cross_validations = {\n",
    "        metric: CrossValidator(\n",
    "            estimator=classifier,\n",
    "            estimatorParamMaps=hyperparams_grid,\n",
    "            evaluator=cv_evaluators[metric],\n",
    "            numFolds=NUM_FOLDS_CV,\n",
    "            collectSubModels=True\n",
    "        )\n",
    "        for metric in cv_evaluation_metrics\n",
    "    }\n",
    "\n",
    "    cross_validated = dict()\n",
    "\n",
    "    for metric in cv_evaluation_metrics:\n",
    "\n",
    "        cross_validated[metric] = cross_validations[\n",
    "            metric\n",
    "        ].fit(train_df)\n",
    "\n",
    "    if (isinstance(classifier, LinearRegression)):\n",
    "        \n",
    "        for metric in cv_evaluation_metrics:\n",
    "\n",
    "            training_result = cross_validated[\n",
    "                metric\n",
    "            ].bestModel.summary\n",
    "\n",
    "            print(\n",
    "                \"***** Evaluating Training Set, (Linear Regression, best model according to metric {}) *****\".format(\n",
    "                    metric\n",
    "                )\n",
    "            )\n",
    "            print(\"RMSE: {:.3f}\".format(training_result.rootMeanSquaredError))\n",
    "            print(\"R2: {:.3f}\".format(training_result.r2))\n",
    "            print(\"Adjusted R2: {:.3f}\".format(training_result.r2adj))\n",
    "            print()\n",
    "\n",
    "        predictions = {\n",
    "            metric: cross_validated[\n",
    "                metric\n",
    "            ].bestModel.transform(test_df)\n",
    "            for metric in cv_evaluation_metrics\n",
    "        }\n",
    "\n",
    "        for m, model in cross_validated.items():\n",
    "\n",
    "                print(\n",
    "                    \"*** {} Set, (rf, best model elected by {}) ***\".format(\n",
    "                        \"Test\", m\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                for e, evaluator in classifier_evaluators.items():\n",
    "\n",
    "                    print(\n",
    "                        \"{}: {}\".format(\n",
    "                            evaluator.getMetricName(), evaluator.evaluate(\n",
    "                                predictions[m]\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                print(\"*******************************\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        for stage_name, stage_df in zip([\"Train\", \"Test\"], [train_df, test_df]):\n",
    "            predictions = {\n",
    "                metric: cross_validated[\n",
    "                    metric\n",
    "                ].bestModel.transform(stage_df)\n",
    "                for metric in cv_evaluation_metrics\n",
    "            }\n",
    "\n",
    "            for m, model in cross_validated.items():\n",
    "\n",
    "                print(\n",
    "                    \"*** {} Set, (rf, best model elected by {}) ***\".format(\n",
    "                        stage_name, m\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                for e, evaluator in classifier_evaluators.items():\n",
    "\n",
    "                    print(\n",
    "                        \"{}: {}\".format(\n",
    "                            evaluator.getMetricName(), evaluator.evaluate(\n",
    "                                predictions[m]\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                print(\"*******************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_train_df, lr_test_df = feature_selection_train_df, feature_selection_test_df\n",
    "lr_train_df, lr_test_df = learning_train_df, learning_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(\n",
    "    # featuresCol=\"feature_vec_ufs_0.1\", \n",
    "    labelCol=\"points\"\n",
    ")\n",
    "\n",
    "lr_evaluation_metrics = [\"r2\", \"mse\"]\n",
    "lr_evaluation_metrics_cv = [\"r2\"]\n",
    "\n",
    "lr_param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(\n",
    "        lr.featuresCol, [\n",
    "            \"ufs_0-1\", \n",
    "            # \"value_vec_min_max\",\n",
    "            # \"all_vec_min_max_pcs\",\n",
    "            # \"all_vec_min_max\"\n",
    "        ]\n",
    "    )\n",
    "    #TODO add intermediate values: prof uses [0.0, 0.5, 1]\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 1])\n",
    "    #TODO add intermediate values: prof uses [0.0, 0.05, 0.1]\n",
    "    # .addGrid(lr.regParam, [0.0, 0.1])\n",
    "    # .addGrid(lr.fitIntercept, [True, False])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "find_best_regressor(\n",
    "    train_df=lr_train_df, \n",
    "    test_df=lr_test_df, \n",
    "    regressor=lr,\n",
    "    regressor_evaluation_metrics=lr_evaluation_metrics,\n",
    "    cv_evaluation_metrics=lr_evaluation_metrics_cv,\n",
    "    hyperparams_grid=lr_param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_train_df, dt_test_df = feature_selection_train_df, feature_selection_test_df\n",
    "dt_train_df, dt_test_df = learning_train_df, learning_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(\n",
    "    # featuresCol=\"feature_vec\", \n",
    "    labelCol=\"points\"\n",
    ")\n",
    "\n",
    "dt_evaluation_metrics = [\"r2\", \"mse\"]\n",
    "dt_evaluation_metrics_cv = [\"r2\"]\n",
    "\n",
    "dt_param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(\n",
    "        dt.featuresCol, [\n",
    "            \"ufs_0-1\", \n",
    "            # \"value_vec_min_max\",\n",
    "            # \"all_vec_min_max_pcs\",\n",
    "            # \"all_vec_min_max\"\n",
    "        ]\n",
    "    )\n",
    "    # .addGrid(dt.standardization, [True, False])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "find_best_regressor(\n",
    "    train_df=dt_train_df, \n",
    "    test_df=dt_test_df, \n",
    "    regressor=dt,\n",
    "    regressor_evaluation_metrics=dt_evaluation_metrics,\n",
    "    cv_evaluation_metrics=dt_evaluation_metrics_cv,\n",
    "    hyperparams_grid=dt_param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_df, rf_test_df = learning_train_df, learning_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    # featuresCol=\"feature_vec\", \n",
    "    labelCol=\"points\"\n",
    ")\n",
    "\n",
    "rf_evaluation_metrics = [\"r2\", \"mse\"]\n",
    "rf_evaluation_metrics_cv = [\"r2\"]\n",
    "\n",
    "rf_param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(\n",
    "        rf.featuresCol, [\n",
    "            \"ufs_0-1\", \n",
    "            # \"value_vec_min_max\",\n",
    "            # \"all_vec_min_max_pcs\",\n",
    "            # \"all_vec_min_max\"\n",
    "        ]\n",
    "    )\n",
    "    # .addGrid(rf.standardization, [True, False])\n",
    "    .build()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_regressor(\n",
    "    train_df=rf_train_df, \n",
    "    test_df=rf_test_df, \n",
    "    regressor=rf,\n",
    "    regressor_evaluation_metrics=rf_evaluation_metrics,\n",
    "    cv_evaluation_metrics=rf_evaluation_metrics_cv,\n",
    "    hyperparams_grid=rf_param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_train_df, gbt_test_df = learning_train_df, learning_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(\n",
    "    # featuresCol=\"feature_vec\", \n",
    "    labelCol=\"points\"\n",
    ")\n",
    "\n",
    "gbt_evaluation_metrics = [\"r2\", \"mse\"]\n",
    "gbt_evaluation_metrics_cv = [\"r2\"]\n",
    "\n",
    "gbt_param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(\n",
    "        gbt.featuresCol, [\n",
    "            \"ufs_0-1\", \n",
    "            # \"value_vec_min_max\",\n",
    "            # \"all_vec_min_max_pcs\",\n",
    "            # \"all_vec_min_max\"\n",
    "        ]\n",
    "    )\n",
    "    # .addGrid(gbt.standardization, [True, False])\n",
    "    .build()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_regressor(\n",
    "    train_df=gbt_train_df, \n",
    "    test_df=gbt_test_df, \n",
    "    regressor=gbt,\n",
    "    regressor_evaluation_metrics=gbt_evaluation_metrics,\n",
    "    cv_evaluation_metrics=gbt_evaluation_metrics_cv,\n",
    "    hyperparams_grid=gbt_param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO evaluate more advanced, dynamic macro placements\n",
    "def get_macro_place(place, league):\n",
    "\n",
    "    if league == \"German Bundesliga\":\n",
    "        if 1 <= place <= 4:\n",
    "            return 0.0\n",
    "        if 5 <= place <= 7:\n",
    "            return 1.0\n",
    "        if 8 <= place <= 10:\n",
    "            return 2.0\n",
    "        if 11 <= place <= 15:\n",
    "            return 3.0\n",
    "        if 16 <= place <= 18:\n",
    "            return 4.0\n",
    "\n",
    "    elif league == \"Holland Eredivise\":\n",
    "        if place == 1:\n",
    "            return 0.0\n",
    "        if 2 <= place <= 3:\n",
    "            return 1.0\n",
    "        if 4 <= place <= 9:\n",
    "            return 2.0\n",
    "        if 10 <= place <= 15:\n",
    "            return 3.0\n",
    "        if 16 <= place <= 18:\n",
    "            return 4.0\n",
    "\n",
    "\n",
    "    elif league == \"French League 1\":\n",
    "        if 1 <= place <= 2:\n",
    "            return 0.0\n",
    "        if 3 <= place <= 5:\n",
    "            return 1.0\n",
    "        if 6 <= place <= 11:\n",
    "            return 2.0\n",
    "        if 12 <= place <= 17:\n",
    "            return 3.0\n",
    "        if 18 <= place <= 20:\n",
    "            return  4.0\n",
    "    \n",
    "    else: #It, Sp, En\n",
    "        if 1 <= place <= 4:\n",
    "            return 0.0\n",
    "        if 5 <= place <= 7:\n",
    "            return 1.0\n",
    "        if 8 <= place <= 12:\n",
    "            return 2.0\n",
    "        if 13 <= place <= 17:\n",
    "            return 3.0\n",
    "        if 18 <= place <= 20:\n",
    "            return 4.0\n",
    "\n",
    "    return None\n",
    "\n",
    "get_macro_place_UDF = udf(\n",
    "    lambda place, league: get_macro_place(float(place), league),\n",
    "    DoubleType(),\n",
    ")\n",
    "\n",
    "NUM_MACRO_PLACES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_df = feature_selection_learning_df\n",
    "classification_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = classification_df.withColumn(\n",
    "    \"macro_place\", get_macro_place_UDF(col(\"place\"), col(\"League\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_train_df, classification_test_df = classification_df.randomSplit(\n",
    "    # [0.9,0.1]\n",
    "    # NOTE reactive 90/10 split, keep 70/30 just when using one league\n",
    "    [0.7,0.3]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_distribution(\n",
    "    classification_df.toPandas(), \n",
    "    [\"macro_place\"], \n",
    "    color = \"teal\", \n",
    "    figsize=(10,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train_df, svm_test_df = classification_train_df, classification_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(\n",
    "    featuresCol=\"ufs_0-1\", \n",
    "    labelCol=\"macro_place\"\n",
    ")\n",
    "\n",
    "ovr = OneVsRest(\n",
    "    classifier=svm,\n",
    "    featuresCol=\"feature_vec_ufs_0-1\", \n",
    "    labelCol=\"macro_place\"\n",
    ")\n",
    "\n",
    "svm_evaluation_metrics = [\"accuracy\"]\n",
    "svm_evaluation_metrics_cv = [\"accuracy\"]\n",
    "\n",
    "svm_param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(\n",
    "        ovr.featuresCol, [\n",
    "            \"ufs_0-1\", \n",
    "            \"value_vec_min_max\",\n",
    "            # \"all_vec_min_max_pcs\",\n",
    "            # \"all_vec_min_max\"\n",
    "        ]\n",
    "    )\n",
    "    .build()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_best_classifier(\n",
    "#     train_df=svm_train_df, \n",
    "#     test_df=svm_test_df, \n",
    "#     classifier=ovr,\n",
    "#     classifier_evaluation_metrics=svm_evaluation_metrics,\n",
    "#     cv_evaluation_metrics=svm_evaluation_metrics_cv,\n",
    "#     hyperparams_grid=svm_param_grid\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor_train_df, lor_test_df = classification_train_df, classification_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO same as SVM\n",
    "\n",
    "lor = LogisticRegression(\n",
    "    # featuresCol=\"ufs_0-1\", \n",
    "    labelCol=\"macro_place\"\n",
    ")\n",
    "\n",
    "ovr = OneVsRest(\n",
    "    classifier=lor,\n",
    "    # featuresCol=\"ufs_0-1\", \n",
    "    labelCol=\"macro_place\"\n",
    ")\n",
    "\n",
    "lor_evaluation_metrics = [\"accuracy\"]\n",
    "lor_evaluation_metrics_cv = [\"accuracy\"]\n",
    "\n",
    "lor_param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(\n",
    "        ovr.featuresCol, [\n",
    "            \"ufs_0-1\", \n",
    "            \"value_vec_min_max\",\n",
    "            # \"all_vec_min_max_pcs\",\n",
    "            # \"all_vec_min_max\"\n",
    "        ]\n",
    "    )\n",
    "    .build()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_classifier(\n",
    "    train_df=lor_train_df, \n",
    "    test_df=lor_test_df, \n",
    "    classifier=ovr,\n",
    "    classifier_evaluation_metrics=lor_evaluation_metrics,\n",
    "    cv_evaluation_metrics=lor_evaluation_metrics_cv,\n",
    "    hyperparams_grid=lor_param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_train_df, ct_test_df = classification_train_df, classification_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = DecisionTreeClassifier(\n",
    "    # featuresCol=\"ufs_0-1\", \n",
    "    labelCol=\"macro_place\"\n",
    ")\n",
    "\n",
    "# ovr = OneVsRest(\n",
    "#     classifier=ct,\n",
    "#     featuresCol=\"feature_vec_ufs_0-1\", \n",
    "#     labelCol=\"macro_place\"\n",
    "# )\n",
    "\n",
    "ct_evaluation_metrics = [\"accuracy\"]\n",
    "ct_evaluation_metrics_cv = [\"accuracy\"]\n",
    "\n",
    "ct_param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(\n",
    "        ct.featuresCol, [\n",
    "            \"ufs_0-1\", \n",
    "            # \"value_vec_min_max\",\n",
    "            # \"all_vec_min_max_pcs\",\n",
    "            # \"all_vec_min_max\"\n",
    "        ]\n",
    "    )\n",
    "    .build()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_classifier(\n",
    "    train_df=ct_train_df, \n",
    "    test_df=ct_test_df, \n",
    "    classifier=ct,\n",
    "    classifier_evaluation_metrics=ct_evaluation_metrics,\n",
    "    cv_evaluation_metrics=ct_evaluation_metrics_cv,\n",
    "    hyperparams_grid=ct_param_grid\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_train_df, rfc_test_df = classification_train_df, classification_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    # featuresCol=\"feature_vec_ufs_0-1\", \n",
    "    labelCol=\"macro_place\"\n",
    ")\n",
    "\n",
    "# ovr = OneVsRest(\n",
    "#     classifier=rfc,\n",
    "#     featuresCol=\"feature_vec_ufs_0-1\", \n",
    "#     labelCol=\"macro_place\"\n",
    "# )\n",
    "\n",
    "rfc_evaluation_metrics = [\"accuracy\"]\n",
    "rfc_evaluation_metrics_cv = [\"accuracy\"]\n",
    "\n",
    "rfc_param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(\n",
    "        rfc.featuresCol, [\n",
    "            \"ufs_0-1\", \n",
    "            # \"value_vec_min_max\",\n",
    "            # \"all_vec_min_max_pcs\",\n",
    "            # \"all_vec_min_max\"\n",
    "        ]\n",
    "    )\n",
    "    .build()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_classifier(\n",
    "    train_df=rfc_train_df, \n",
    "    test_df=rfc_test_df, \n",
    "    classifier=rfc,\n",
    "    classifier_evaluation_metrics=rfc_evaluation_metrics,\n",
    "    cv_evaluation_metrics=rfc_evaluation_metrics_cv,\n",
    "    hyperparams_grid=rfc_param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_train_df, mlp_test_df = classification_train_df, classification_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MultilayerPerceptronClassifier(\n",
    "    # featuresCol=\"feature_vec_ufs_0-1\", \n",
    "    labelCol=\"macro_place\"\n",
    ")\n",
    "\n",
    "# ovr = OneVsRest(\n",
    "#     classifier=mlp,\n",
    "#     featuresCol=\"feature_vec_ufs_0-1\", \n",
    "#     labelCol=\"macro_place\"\n",
    "# )\n",
    "\n",
    "mlp_evaluation_metrics = [\"accuracy\"]\n",
    "mlp_evaluation_metrics_cv = [\"accuracy\"]\n",
    "\n",
    "mlp_param_grid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(mlp.layers, [[NUM_FEATURES, 4, 4, 2, NUM_MACRO_PLACES]])\n",
    "    .addGrid(\n",
    "        mlp.featuresCol, [\n",
    "            \"ufs_0-1\", \n",
    "            # \"value_vec_min_max\",\n",
    "            # \"all_vec_min_max_pcs\",\n",
    "            # \"all_vec_min_max\"\n",
    "        ]\n",
    "    )\n",
    "    .build()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_classifier(\n",
    "    train_df=mlp_train_df, \n",
    "    test_df=mlp_test_df, \n",
    "    classifier=mlp,\n",
    "    classifier_evaluation_metrics=mlp_evaluation_metrics,\n",
    "    cv_evaluation_metrics=mlp_evaluation_metrics_cv,\n",
    "    hyperparams_grid=mlp_param_grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom ranking-based evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare ranking of prediction value with actual ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 3: clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "clustering_df = pre_processed_df\n",
    "\n",
    "CLUSTERING_FEATURES = copy.deepcopy(PLAYER_FEATURES)\n",
    "CLUSTERING_FEATURES.remove(\"overall\")\n",
    "CLUSTERING_FEATURES.remove(\"value\")\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=CLUSTERING_FEATURES, outputCol=\"all_vec\"\n",
    ")\n",
    "\n",
    "clustering_df = assembler.transform(clustering_df)\n",
    "\n",
    "scaler = MinMaxScaler(\n",
    "    inputCol=\"all_vec\", outputCol=\"all_vec_min_max\"\n",
    ")\n",
    "\n",
    "clustering_df = scaler.fit(clustering_df).transform(clustering_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(\n",
    "    dataset,\n",
    "    n_clusters,\n",
    "    distance_measure=\"euclidean\",\n",
    "    max_iter=20,\n",
    "    features_col=\"features\",\n",
    "    prediction_col=\"cluster\",\n",
    "    random_seed=RANDOM_SEED,\n",
    "):\n",
    "\n",
    "    print(\n",
    "        f\"\"\"Training K-means clustering using the following parameters: \n",
    "        - K (n. of clusters) = {n_clusters}\n",
    "        - max_iter (max n. of iterations) = {max_iter}\n",
    "        - distance measure = {distance_measure}\n",
    "        - random seed = {random_seed if random_seed is not None else \"NONE USED!\"}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    if distance_measure == \"cosine\":\n",
    "\n",
    "        # Normalize inputs to unit-length vectors\n",
    "        dataset = Normalizer(\n",
    "            inputCol=features_col, outputCol=features_col + \"_norm\", p=1\n",
    "        ).transform(dataset)\n",
    "\n",
    "        features_col = features_col + \"_norm\"\n",
    "\n",
    "    # Train a K-means model\n",
    "    kmeans = KMeans(\n",
    "        featuresCol=features_col,\n",
    "        predictionCol=prediction_col,\n",
    "        k=n_clusters,\n",
    "        initMode=\"k-means||\",\n",
    "        initSteps=5,\n",
    "        tol=0.000001,\n",
    "        maxIter=max_iter,\n",
    "        # seed=random_seed,\n",
    "        distanceMeasure=distance_measure,\n",
    "    )\n",
    "\n",
    "    model = kmeans.fit(dataset)\n",
    "    # here there are all the relevant clustering information\n",
    "\n",
    "    # Make clusters\n",
    "    clusters_df = model.transform(dataset)\n",
    "\n",
    "    return model, clusters_df\n",
    "\n",
    "\n",
    "def evaluate_k_means(\n",
    "    clusters,\n",
    "    metric_name=\"silhouette\",\n",
    "    distance_measure=\"squaredEuclidean\",  # cosine\n",
    "    prediction_col=\"cluster\",\n",
    "    featuresCol = \"features\"\n",
    "):\n",
    "\n",
    "    # Evaluate clustering by computing Silhouette score\n",
    "    evaluator = ClusteringEvaluator(\n",
    "        metricName=metric_name,\n",
    "        distanceMeasure=distance_measure,\n",
    "        predictionCol=prediction_col,\n",
    "        featuresCol=featuresCol\n",
    "    )\n",
    "\n",
    "    return evaluator.evaluate(clusters)\n",
    "\n",
    "\n",
    "def do_clustering(\n",
    "    max_k_clusters, \n",
    "    input_df, \n",
    "    max_iter,\n",
    "    featuresCol,\n",
    "    clusterCol\n",
    "):\n",
    "    clustering_results = {}\n",
    "\n",
    "    clusters_df = input_df\n",
    "\n",
    "    # for k in tqdm( range(5, max_k_clusters + 1, 5), desc = \"Performing clustering\" ):\n",
    "    for k in tqdm(range(2, max_k_clusters + 1, 4), desc=\"Performing clustering\"):\n",
    "\n",
    "        print(f\"Running K-means using K = {k}\")\n",
    "\n",
    "        # model, clusters_df = k_means(tf_idf_df, k, max_iter=50, distance_measure=\"cosine\") # Alternatively, distance_measure=\"euclidean\"\n",
    "        # model, clusters_df = k_means(input_df, k, max_iter=max_iter, distance_measure=\"cosine\") # Alternatively, distance_measure=\"euclidean\"\n",
    "        model, clusters_df = k_means(\n",
    "            # input_df,\n",
    "            clusters_df, \n",
    "            k, \n",
    "            max_iter=max_iter, \n",
    "            distance_measure=\"euclidean\", \n",
    "            features_col=featuresCol,\n",
    "            prediction_col=clusterCol + \"_k_\" + str(k),\n",
    "        )  # Alternatively, distance_measure=\"euclidean\"\n",
    "        # silhouette_k = evaluate_k_means(clusters_df, distance_measure=\"cosine\") # Alternatively, distance_measure=\"squaredEuclidean\"\n",
    "        silhouette_k = evaluate_k_means(\n",
    "            clusters_df, \n",
    "            distance_measure=\"squaredEuclidean\",\n",
    "            prediction_col=clusterCol + \"_k_\" + str(k),\n",
    "            featuresCol=featuresCol\n",
    "\n",
    "        )  # Alternatively, distance_measure=\"squaredEuclidean\"\n",
    "        # wssd_k = model.summary.trainingCost\n",
    "        wssd_k = model.summary\n",
    "\n",
    "        print(\n",
    "            \"Silhouette coefficient computed with cosine distance: {:.3f}\".format(\n",
    "                silhouette_k\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"Within-cluster Sum of Squared Distances (using cosine distance): {:.3f}\".format(\n",
    "                wssd_k.trainingCost\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"--------------------------------------------------------------------------------------\"\n",
    "        )\n",
    "\n",
    "        l = list(\n",
    "            enumerate(\n",
    "                model.clusterCenters()\n",
    "            )\n",
    "        )\n",
    "        l = [(ind, DenseVector(c)) for ind, c in l]\n",
    "        # print(l)\n",
    "        schema = [\"cluster_id\"  + \"_k_\" + str(k), \"centroid\"  + \"_k_\" + str(k)]\n",
    "\n",
    "        schema = StructType([ \n",
    "            StructField(\"cluster_id\" + \"_k_\" + str(k),IntegerType(),True), \n",
    "            StructField(\"centroid\" + \"_k_\" + str(k),VectorUDT(),True), \n",
    "        ])\n",
    "        centr_df = spark.createDataFrame(data=l, schema=schema)\n",
    "\n",
    "        # centr_df.show()\n",
    "\n",
    "        # df_with_centroids = clusters_df.join(\n",
    "        #     centr_df, on=[\"cluster_id\"]\n",
    "        # )\n",
    "\n",
    "        clusters_df = clusters_df.join(\n",
    "            centr_df, on=[\"cluster_id\" + \"_k_\" + str(k)]\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        clustering_results[str(k)] = {\n",
    "            \"silhouette_k\"      : silhouette_k,\n",
    "            \"wssd_k\"            : wssd_k,\n",
    "            \"model\"             : model,\n",
    "            \"df\"                : clusters_df,\n",
    "            # \"cluster_centroids\" : model.clusterCenters(),\n",
    "            # \"centr_df\" : centr_df,\n",
    "            # \"df_with_centroids\" : df_with_centroids\n",
    "        }\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        # Free up memory space at the end of each iteration\n",
    "        # del model\n",
    "        # del clusters_df\n",
    "        # gc.collect() # garbage collector\n",
    "    \n",
    "    clustering_results[\"df_with_centroid_full\"] = clusters_df\n",
    "\n",
    "    return clustering_results\n",
    "\n",
    "\n",
    "def plot_clustering_results(clustering_results):\n",
    "    # load the dictionary into pandas\n",
    "    df = pd.DataFrame.from_dict(clustering_results, orient=\"index\").reset_index()\n",
    "    df.columns = [\"K\", \"Silhouette\", \"WSSD\"]\n",
    "    # Create a 1x1 figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "    _ = sns.pointplot(data=df, x=\"K\", y=\"WSSD\", ax=ax, color=\"orangered\")\n",
    "    _ = ax.set_xlabel(\"K\")\n",
    "    _ = ax.set_ylabel(\"WSSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_df_dict = {\n",
    "    s: clustering_df.filter(col(\"season\") == s) for s in seasons\n",
    "}\n",
    "\n",
    "MAX_K_CLUSTERS = 8\n",
    "MAX_ITER = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing clustering:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running K-means using K = 2\n",
      "Training K-means clustering using the following parameters: \n",
      "        - K (n. of clusters) = 2\n",
      "        - max_iter (max n. of iterations) = 4\n",
      "        - distance measure = euclidean\n",
      "        - random seed = NONE USED!\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing clustering:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:09<00:09,  9.12s/it]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette coefficient computed with cosine distance: 0.832\n",
      "Within-cluster Sum of Squared Distances (using cosine distance): 366.828\n",
      "--------------------------------------------------------------------------------------\n",
      "Running K-means using K = 6\n",
      "Training K-means clustering using the following parameters: \n",
      "        - K (n. of clusters) = 6\n",
      "        - max_iter (max n. of iterations) = 4\n",
      "        - distance measure = euclidean\n",
      "        - random seed = NONE USED!\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing clustering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:15<00:00,  7.88s/it]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette coefficient computed with cosine distance: 0.394\n",
      "Within-cluster Sum of Squared Distances (using cosine distance): 180.719\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing clustering:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running K-means using K = 2\n",
      "Training K-means clustering using the following parameters: \n",
      "        - K (n. of clusters) = 2\n",
      "        - max_iter (max n. of iterations) = 4\n",
      "        - distance measure = euclidean\n",
      "        - random seed = NONE USED!\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing clustering:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:04<00:04,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette coefficient computed with cosine distance: 0.819\n",
      "Within-cluster Sum of Squared Distances (using cosine distance): 385.904\n",
      "--------------------------------------------------------------------------------------\n",
      "Running K-means using K = 6\n",
      "Training K-means clustering using the following parameters: \n",
      "        - K (n. of clusters) = 6\n",
      "        - max_iter (max n. of iterations) = 4\n",
      "        - distance measure = euclidean\n",
      "        - random seed = NONE USED!\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing clustering: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette coefficient computed with cosine distance: 0.389\n",
      "Within-cluster Sum of Squared Distances (using cosine distance): 175.867\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clustering_results_dict = dict()\n",
    "\n",
    "for s in seasons:\n",
    "    clustering_results_dict[s] = do_clustering(\n",
    "        MAX_K_CLUSTERS, \n",
    "        clustering_df_dict[s], \n",
    "        MAX_ITER,\n",
    "        \"all_vec_min_max\",\n",
    "        \"cluster_id\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_together_df = reduce(\n",
    "    DataFrame.unionAll, \n",
    "    [\n",
    "        clustering_results_dict[s][\"df_with_centroid_full\"] for s in seasons\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cluster_id_k_6: integer (nullable = false)\n",
      " |-- cluster_id_k_2: integer (nullable = false)\n",
      " |-- short_name: string (nullable = true)\n",
      " |-- club_name: string (nullable = true)\n",
      " |-- league_name: string (nullable = true)\n",
      " |-- season: string (nullable = true)\n",
      " |-- player_positions: string (nullable = true)\n",
      " |-- macro_role: string (nullable = true)\n",
      " |-- overall: integer (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- pace: integer (nullable = true)\n",
      " |-- shooting: integer (nullable = true)\n",
      " |-- passing: integer (nullable = true)\n",
      " |-- dribbling: integer (nullable = true)\n",
      " |-- defending: integer (nullable = true)\n",
      " |-- physic: integer (nullable = true)\n",
      " |-- attacking_crossing: integer (nullable = true)\n",
      " |-- attacking_finishing: integer (nullable = true)\n",
      " |-- attacking_heading_accuracy: integer (nullable = true)\n",
      " |-- attacking_short_passing: integer (nullable = true)\n",
      " |-- skill_dribbling: integer (nullable = true)\n",
      " |-- skill_fk_accuracy: integer (nullable = true)\n",
      " |-- skill_long_passing: integer (nullable = true)\n",
      " |-- skill_ball_control: integer (nullable = true)\n",
      " |-- movement_acceleration: integer (nullable = true)\n",
      " |-- movement_sprint_speed: integer (nullable = true)\n",
      " |-- movement_reactions: integer (nullable = true)\n",
      " |-- power_shot_power: integer (nullable = true)\n",
      " |-- power_stamina: integer (nullable = true)\n",
      " |-- power_strength: integer (nullable = true)\n",
      " |-- power_long_shots: integer (nullable = true)\n",
      " |-- mentality_aggression: integer (nullable = true)\n",
      " |-- mentality_penalties: integer (nullable = true)\n",
      " |-- defending_standing_tackle: integer (nullable = true)\n",
      " |-- all_vec: vector (nullable = true)\n",
      " |-- all_vec_min_max: vector (nullable = true)\n",
      " |-- centroid_k_2: vector (nullable = true)\n",
      " |-- centroid_k_6: vector (nullable = true)\n",
      " |-- distance_from_centroid_k_2: float (nullable = true)\n",
      " |-- distance_from_centroid_k_6: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_together_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO select K according to clustering evaluation\n",
    "\n",
    "K = [\"2\",\"6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute distance between player and centroid of its cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_distance_from_centroid_UDF = udf(\n",
    "    lambda player, centroid: float(\n",
    "        Vectors.squared_distance(\n",
    "            player, centroid\n",
    "        )\n",
    "    ), FloatType()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in K:\n",
    "    all_together_df = all_together_df.withColumn(\n",
    "        \"distance_from_centroid\" + \"_k_\" + str(k),\n",
    "        compute_distance_from_centroid_UDF(\n",
    "            col(\"all_vec_min_max\"),\n",
    "            col(\"centroid\" + \"_k_\" + str(k))\n",
    "        )\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From players to teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df = all_together_df.groupBy(\n",
    "    [\"season\", \"club_name\", \"macro_role\"]\n",
    ").agg(\n",
    "    { \n",
    "        \"distance_from_centroid\" + \"_k_\" + str(k): \"avg\" for k in K \n",
    "    }\n",
    ")\n",
    "\n",
    "for k in K:\n",
    "    teams_df = teams_df.withColumnRenamed(\n",
    "        \"avg(distance_from_centroid\" + \"_k_\" + str(k) + \")\",\n",
    "        \"avg_distance_from_centroid\" + \"_k_\" + str(k)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subquery(macro_role, k):\n",
    "    return f\"\"\"(\n",
    "        case\n",
    "            when macro_role='{macro_role}' then avg_distance_from_centroid_k_{k} \n",
    "        else NULL\n",
    "        end\n",
    "    ) as avg_dist_macro_role_{int(macro_role)}_k_{k}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df.createOrReplaceTempView(\"t\")\n",
    "\n",
    "temp = dict()\n",
    "\n",
    "for k in K:\n",
    "\n",
    "    temp[k] = (\n",
    "        spark.sql(\n",
    "            f\"\"\"\n",
    "                select season, club_name, {generate_subquery(0.0, k)}, {generate_subquery(1.0, k)}, {generate_subquery(2.0, k)}, {generate_subquery(3.0, k)}, {generate_subquery(4.0, k)}, {generate_subquery(5.0, k)}, {generate_subquery(6.0, k)}, {generate_subquery(7.0, k)}\n",
    "                from t\n",
    "            \"\"\"\n",
    "        )\n",
    "        .groupBy(\"season\", \"club_name\")\n",
    "        .agg(\n",
    "            # TODO use for loop as in second cell of \"from players to teams\"\n",
    "            sum(f\"avg_dist_macro_role_0_k_{k}\").alias(f\"avg_dist_macro_role_0_k_{k}\"),\n",
    "            sum(f\"avg_dist_macro_role_1_k_{k}\").alias(f\"avg_dist_macro_role_1_k_{k}\"),\n",
    "            sum(f\"avg_dist_macro_role_2_k_{k}\").alias(f\"avg_dist_macro_role_2_k_{k}\"),\n",
    "            sum(f\"avg_dist_macro_role_3_k_{k}\").alias(f\"avg_dist_macro_role_3_k_{k}\"),\n",
    "            sum(f\"avg_dist_macro_role_4_k_{k}\").alias(f\"avg_dist_macro_role_4_k_{k}\"),\n",
    "            sum(f\"avg_dist_macro_role_5_k_{k}\").alias(f\"avg_dist_macro_role_5_k_{k}\"),\n",
    "            sum(f\"avg_dist_macro_role_6_k_{k}\").alias(f\"avg_dist_macro_role_6_k_{k}\"),\n",
    "            sum(f\"avg_dist_macro_role_7_k_{k}\").alias(f\"avg_dist_macro_role_7_k_{k}\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE executing this cell n times, w/o restoring teams_df --> \n",
    "# n copies of avg_dist_macro_role_[0:7]_k_[2, 6]\n",
    "\n",
    "teams_df = temp[str(K[0])]\n",
    "\n",
    "for i in range(1, len(K)):\n",
    "    teams_df = teams_df.join(\n",
    "        temp[str(K[i])], on=[\"season\", \"club_name\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teams_df = teams_df.fillna(-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "|season|           club_name|avg_dist_macro_role_0_k_2|avg_dist_macro_role_1_k_2|avg_dist_macro_role_2_k_2|avg_dist_macro_role_3_k_2|avg_dist_macro_role_4_k_2|avg_dist_macro_role_5_k_2|avg_dist_macro_role_6_k_2|avg_dist_macro_role_7_k_2|avg_dist_macro_role_0_k_6|avg_dist_macro_role_1_k_6|avg_dist_macro_role_2_k_6|avg_dist_macro_role_3_k_6|avg_dist_macro_role_4_k_6|avg_dist_macro_role_5_k_6|avg_dist_macro_role_6_k_6|avg_dist_macro_role_7_k_6|\n",
      "+------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "|    20|         Real Madrid|      0.13310935255140066|       0.6452527642250061|       0.7285355508327485|        1.157500982284546|        0.871081992983818|       0.6796806454658508|       0.8522399167219797|        0.805506432056427|      0.13310935255140066|       0.3338129222393036|       0.4461956024169922|       0.5169087052345276|       0.5049688667058945|      0.27167631685733795|       0.2865249887108803|      0.31541445553302766|\n",
      "|    20|     AtlÃ©tico Madrid|       0.2273107667764028|       0.5647262930870056|         1.02837672829628|                     null|       0.6670483499765396|                     null|                     null|       0.6998137633005778|       0.2273107667764028|      0.26262302324175835|       0.3376410812139511|                     null|       0.2515212050997294|                     null|                     null|       0.3298549900452296|\n",
      "|    19|           Getafe CF|      0.18396138027310371|       0.4614099085330963|       1.3677110552787781|       0.6238859295845032|      0.39780097348349436|       0.5464516878128052|                     null|       0.9184017062187195|      0.17675704658031463|      0.16086379289627076|       0.4240179151296616|       0.5019751638174057|      0.20651001589638845|      0.31192415952682495|                     null|      0.47099049389362335|\n",
      "|    19|            SD Eibar|      0.16288764029741287|        0.364567032456398|       1.0135307439735957|      0.47893792390823364|       0.6763311454227993|                     null|                     null|      0.47637004405260086|       0.1623469479382038|       0.2439548283815384|       0.3569730392524174|       0.2937618171175321|      0.42997817269393374|                     null|                     null|       0.2068634293973446|\n",
      "|    19|    Deportivo AlavÃ©s|      0.13154368102550507|      0.46336327493190765|        1.166532650589943|       0.4683908025423686|       0.4906241700053215|                     null|                     null|       0.7384517431259155|      0.13202214737733206|       0.3028704524040222|      0.25849540407458943|       0.2458489934603373|       0.2584315396845341|                     null|                     null|       0.3331674292683601|\n",
      "|    19|          Levante UD|       0.1188961702088515|       0.2869564912148884|       0.8241235196590424|       0.3450799882411957|       0.6284084071715673|       0.5032863095402718|                     null|       0.5266375303268432|      0.11554042001565297|      0.21187701395579747|      0.21011700183153154|      0.26050176844000816|      0.23181475326418877|      0.16162574291229248|                     null|      0.20786157995462418|\n",
      "|    19|  Real Valladolid CF|      0.23330388218164444|      0.28802480176091194|        0.862929622332255|       0.5669426284730434|       0.5116569929652743|       1.1603126525878906|                     null|       0.6940286954243978|      0.22652815779050192|      0.28505128622055054|      0.18898430715004602|      0.17845139279961586|      0.32542509502834743|       0.3774608373641968|                     null|      0.31598110993703205|\n",
      "|    20|       Real Sociedad|      0.11184458931287129|       0.4659169390797615|       1.1701987147331239|      0.49044619500637054|      0.34400472790002823|       1.0464909374713898|       0.8347765377589634|       0.8519961088895798|      0.11184458931287129|      0.25742589868605137|       0.3410784587264061|       0.1907106339931488|       0.2648012737433116|       0.5558691620826721|       0.3081330380269459|       0.3491248209029436|\n",
      "|    19|        RCD Mallorca|       0.2009385128815969|       0.4413555711507797|       0.9887268900871277|        0.292383149266243|       0.5772754574815432|       0.5251393616199493|                     null|       0.6172397911548615|      0.19642811516920725|      0.36617109179496765|      0.26823104321956637|        0.199545718729496|      0.28805194546778995|      0.26004649698734283|                     null|      0.41362247467041013|\n",
      "|    19|       Villarreal CF|      0.16336939732233682|       0.3315502405166626|       0.8774935205777487|       0.2557102342446645|       0.6599699242247475|       0.7699575424194336|                     null|       0.6749794960021973|      0.16379109770059586|       0.2134241595864296|        0.293966439863046|      0.17911901324987411|      0.42150263984998065|      0.22500190138816833|                     null|      0.18979757130146027|\n",
      "|    19|          Real Betis|      0.11722802619139354|      0.41816145181655884|       0.6918608367443084|         0.72795769572258|      0.45196392983198164|       0.8468217551708221|       0.7575444206595421|        0.907449334859848|      0.11061299343903859|      0.18889714032411575|      0.22001413404941558|       0.5118765980005264|      0.31243121698498727|       0.3285170644521713|      0.21867239102721214|       0.3662258982658386|\n",
      "|    19|     AtlÃ©tico Madrid|      0.30038780470689136|       0.6275266826152801|       1.0538001507520676|       0.3735186457633972|       0.6170483595795102|                     null|       0.9585416913032532|       0.7154351957142353|      0.29936840136845905|      0.25339133441448214|       0.3037826468547185|      0.17898039519786835|      0.22624784211317697|                     null|      0.17974579334259033|       0.2673742240294814|\n",
      "|    19|          CA Osasuna|       0.1701824553310871|       0.5015701092779636|       0.8444112360477447|      0.33172838389873505|       0.3829645197838545|       0.4593929648399353|                     null|       0.5629642128944397|      0.17230880819261074|      0.28198354318737984|       0.3513019621372223|      0.17647884289423624|      0.17892803996801376|       0.2872597575187683|                     null|       0.1852712631225586|\n",
      "|    20|    Deportivo AlavÃ©s|      0.13139229826629162|       0.6201390794345311|       1.0954987049102782|                     null|       0.4611586630344391|                     null|                     null|       0.6024654731154442|      0.13139229826629162|       0.3922693920986993|      0.31999213099479673|                     null|       0.2582198745356156|                     null|                     null|        0.346450287848711|\n",
      "|    20|          Sevilla FC|      0.13481800071895123|       0.6757308294375738|       0.7631292939186096|       0.5491022244095802|      0.48850564445768085|      0.44674524664878845|       1.0879677931467693|       0.6261876374483109|      0.13481800071895123|        0.372043843070666|       0.3296275921165943|      0.21997222304344177|        0.308693921991757|      0.25369784235954285|       0.5105850696563721|       0.3762353528290987|\n",
      "|    20|          Real Betis|        0.223610083758831|      0.45808588713407516|       0.5135776698589325|       0.5692213773727417|      0.40295011632972294|       0.9212265014648438|       0.5270781417687734|       0.7187129497528076|        0.223610083758831|       0.2410015407949686|      0.23169560357928276|       0.3197457268834114|      0.21925564441415998|       0.2879308760166168|       0.2698853611946106|      0.34451334178447723|\n",
      "|    19|Athletic Club de ...|       0.1410832405090332|       0.4622919838875532|       0.9287812486290932|                     null|       0.5885321032255888|        0.837454617023468|       0.4574582725763321|       0.6922027230262756|      0.14165501203387976|      0.27476092241704464|      0.23541311919689178|                     null|       0.3994348496198654|       0.5181042104959488|      0.34880536794662476|      0.43517429530620577|\n",
      "|    20|           SD Huesca|      0.16722705711921057|       0.3624255607525508|       1.0856523911158245|      0.42652782797813416|       0.5261619748039679|      0.22960874438285828|       0.6763884425163269|      0.49396536499261856|      0.16722705711921057|       0.2703209879497687|       0.3427559435367584|      0.33015936613082886|       0.3213790241967548|      0.25310173630714417|      0.16979874670505524|      0.23044949769973755|\n",
      "|    20|        FC Barcelona|      0.43694546818733215|       0.5621862769126892|         0.73206747174263|       0.9132073521614075|      0.39393655955791473|       0.5326567143201828|        0.882788305481275|        0.889985978603363|      0.43694546818733215|      0.29841396808624265|       0.3006210088729858|       0.5154942870140076|       0.2820944720879197|      0.25355029106140137|      0.31524763256311417|       0.3326510526239872|\n",
      "|    19|          Sevilla FC|       0.1609111037105322|      0.33888248602549237|        0.772539096219199|       0.6061883717775345|       0.6142619468949058|                     null|       1.2246057987213135|       0.6634905536969503|      0.16037432104349136|      0.13124597569306692|       0.2758501831974302|      0.32664523646235466|       0.2654028514569456|                     null|      0.30607253313064575|      0.25148043036460876|\n",
      "+------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_distances_dict = dict()\n",
    "\n",
    "for k in K:\n",
    "    \n",
    "    avg_distances_dict[k] = [\n",
    "        f\"avg_dist_macro_role_{i}_k_{k}\" for i in range(0, NUM_MACRO_ROLES)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "\n",
    "global_max = teams_df.select(\n",
    "    greatest(\n",
    "        *list(\n",
    "            itertools.chain.from_iterable(\n",
    "                avg_distances_dict.values()\n",
    "            )\n",
    "        )\n",
    "    ).alias(\"row_wise_max\")\n",
    ").collect()\n",
    "\n",
    "global_max = [row[\"row_wise_max\"] for row in global_max]\n",
    "\n",
    "global_max = builtins.max(global_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df = teams_df.fillna(global_max * 1.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+--------------------+\n",
      "|season|           club_name|avg_dist_macro_role_0_k_2|avg_dist_macro_role_1_k_2|avg_dist_macro_role_2_k_2|avg_dist_macro_role_3_k_2|avg_dist_macro_role_4_k_2|avg_dist_macro_role_5_k_2|avg_dist_macro_role_6_k_2|avg_dist_macro_role_7_k_2|avg_dist_macro_role_0_k_6|avg_dist_macro_role_1_k_6|avg_dist_macro_role_2_k_6|avg_dist_macro_role_3_k_6|avg_dist_macro_role_4_k_6|avg_dist_macro_role_5_k_6|avg_dist_macro_role_6_k_6|avg_dist_macro_role_7_k_6|    avg_dist_vec_k_2|\n",
      "+------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+--------------------+\n",
      "|    20|         Real Madrid|      0.13310935255140066|       0.6452527642250061|       0.7285355508327485|        1.157500982284546|        0.871081992983818|       0.6796806454658508|       0.8522399167219797|        0.805506432056427|      0.13310935255140066|       0.3338129222393036|       0.4461956024169922|       0.5169087052345276|       0.5049688667058945|      0.27167631685733795|       0.2865249887108803|      0.31541445553302766|[0.13310935255140...|\n",
      "|    20|     AtlÃ©tico Madrid|       0.2273107667764028|       0.5647262930870056|         1.02837672829628|        2.286249428987503|       0.6670483499765396|        2.286249428987503|        2.286249428987503|       0.6998137633005778|       0.2273107667764028|      0.26262302324175835|       0.3376410812139511|        2.286249428987503|       0.2515212050997294|        2.286249428987503|        2.286249428987503|       0.3298549900452296|[0.22731076677640...|\n",
      "|    19|           Getafe CF|      0.18396138027310371|       0.4614099085330963|       1.3677110552787781|       0.6238859295845032|      0.39780097348349436|       0.5464516878128052|        2.286249428987503|       0.9184017062187195|      0.17675704658031463|      0.16086379289627076|       0.4240179151296616|       0.5019751638174057|      0.20651001589638845|      0.31192415952682495|        2.286249428987503|      0.47099049389362335|[0.18396138027310...|\n",
      "|    19|            SD Eibar|      0.16288764029741287|        0.364567032456398|       1.0135307439735957|      0.47893792390823364|       0.6763311454227993|        2.286249428987503|        2.286249428987503|      0.47637004405260086|       0.1623469479382038|       0.2439548283815384|       0.3569730392524174|       0.2937618171175321|      0.42997817269393374|        2.286249428987503|        2.286249428987503|       0.2068634293973446|[0.16288764029741...|\n",
      "|    19|    Deportivo AlavÃ©s|      0.13154368102550507|      0.46336327493190765|        1.166532650589943|       0.4683908025423686|       0.4906241700053215|        2.286249428987503|        2.286249428987503|       0.7384517431259155|      0.13202214737733206|       0.3028704524040222|      0.25849540407458943|       0.2458489934603373|       0.2584315396845341|        2.286249428987503|        2.286249428987503|       0.3331674292683601|[0.13154368102550...|\n",
      "|    19|          Levante UD|       0.1188961702088515|       0.2869564912148884|       0.8241235196590424|       0.3450799882411957|       0.6284084071715673|       0.5032863095402718|        2.286249428987503|       0.5266375303268432|      0.11554042001565297|      0.21187701395579747|      0.21011700183153154|      0.26050176844000816|      0.23181475326418877|      0.16162574291229248|        2.286249428987503|      0.20786157995462418|[0.11889617020885...|\n",
      "|    19|  Real Valladolid CF|      0.23330388218164444|      0.28802480176091194|        0.862929622332255|       0.5669426284730434|       0.5116569929652743|       1.1603126525878906|        2.286249428987503|       0.6940286954243978|      0.22652815779050192|      0.28505128622055054|      0.18898430715004602|      0.17845139279961586|      0.32542509502834743|       0.3774608373641968|        2.286249428987503|      0.31598110993703205|[0.23330388218164...|\n",
      "|    20|       Real Sociedad|      0.11184458931287129|       0.4659169390797615|       1.1701987147331239|      0.49044619500637054|      0.34400472790002823|       1.0464909374713898|       0.8347765377589634|       0.8519961088895798|      0.11184458931287129|      0.25742589868605137|       0.3410784587264061|       0.1907106339931488|       0.2648012737433116|       0.5558691620826721|       0.3081330380269459|       0.3491248209029436|[0.11184458931287...|\n",
      "|    19|        RCD Mallorca|       0.2009385128815969|       0.4413555711507797|       0.9887268900871277|        0.292383149266243|       0.5772754574815432|       0.5251393616199493|        2.286249428987503|       0.6172397911548615|      0.19642811516920725|      0.36617109179496765|      0.26823104321956637|        0.199545718729496|      0.28805194546778995|      0.26004649698734283|        2.286249428987503|      0.41362247467041013|[0.20093851288159...|\n",
      "|    19|       Villarreal CF|      0.16336939732233682|       0.3315502405166626|       0.8774935205777487|       0.2557102342446645|       0.6599699242247475|       0.7699575424194336|        2.286249428987503|       0.6749794960021973|      0.16379109770059586|       0.2134241595864296|        0.293966439863046|      0.17911901324987411|      0.42150263984998065|      0.22500190138816833|        2.286249428987503|      0.18979757130146027|[0.16336939732233...|\n",
      "|    19|          Real Betis|      0.11722802619139354|      0.41816145181655884|       0.6918608367443084|         0.72795769572258|      0.45196392983198164|       0.8468217551708221|       0.7575444206595421|        0.907449334859848|      0.11061299343903859|      0.18889714032411575|      0.22001413404941558|       0.5118765980005264|      0.31243121698498727|       0.3285170644521713|      0.21867239102721214|       0.3662258982658386|[0.11722802619139...|\n",
      "|    19|     AtlÃ©tico Madrid|      0.30038780470689136|       0.6275266826152801|       1.0538001507520676|       0.3735186457633972|       0.6170483595795102|        2.286249428987503|       0.9585416913032532|       0.7154351957142353|      0.29936840136845905|      0.25339133441448214|       0.3037826468547185|      0.17898039519786835|      0.22624784211317697|        2.286249428987503|      0.17974579334259033|       0.2673742240294814|[0.30038780470689...|\n",
      "|    19|          CA Osasuna|       0.1701824553310871|       0.5015701092779636|       0.8444112360477447|      0.33172838389873505|       0.3829645197838545|       0.4593929648399353|        2.286249428987503|       0.5629642128944397|      0.17230880819261074|      0.28198354318737984|       0.3513019621372223|      0.17647884289423624|      0.17892803996801376|       0.2872597575187683|        2.286249428987503|       0.1852712631225586|[0.17018245533108...|\n",
      "|    20|    Deportivo AlavÃ©s|      0.13139229826629162|       0.6201390794345311|       1.0954987049102782|        2.286249428987503|       0.4611586630344391|        2.286249428987503|        2.286249428987503|       0.6024654731154442|      0.13139229826629162|       0.3922693920986993|      0.31999213099479673|        2.286249428987503|       0.2582198745356156|        2.286249428987503|        2.286249428987503|        0.346450287848711|[0.13139229826629...|\n",
      "|    20|          Sevilla FC|      0.13481800071895123|       0.6757308294375738|       0.7631292939186096|       0.5491022244095802|      0.48850564445768085|      0.44674524664878845|       1.0879677931467693|       0.6261876374483109|      0.13481800071895123|        0.372043843070666|       0.3296275921165943|      0.21997222304344177|        0.308693921991757|      0.25369784235954285|       0.5105850696563721|       0.3762353528290987|[0.13481800071895...|\n",
      "|    20|          Real Betis|        0.223610083758831|      0.45808588713407516|       0.5135776698589325|       0.5692213773727417|      0.40295011632972294|       0.9212265014648438|       0.5270781417687734|       0.7187129497528076|        0.223610083758831|       0.2410015407949686|      0.23169560357928276|       0.3197457268834114|      0.21925564441415998|       0.2879308760166168|       0.2698853611946106|      0.34451334178447723|[0.22361008375883...|\n",
      "|    19|Athletic Club de ...|       0.1410832405090332|       0.4622919838875532|       0.9287812486290932|        2.286249428987503|       0.5885321032255888|        0.837454617023468|       0.4574582725763321|       0.6922027230262756|      0.14165501203387976|      0.27476092241704464|      0.23541311919689178|        2.286249428987503|       0.3994348496198654|       0.5181042104959488|      0.34880536794662476|      0.43517429530620577|[0.14108324050903...|\n",
      "|    20|           SD Huesca|      0.16722705711921057|       0.3624255607525508|       1.0856523911158245|      0.42652782797813416|       0.5261619748039679|      0.22960874438285828|       0.6763884425163269|      0.49396536499261856|      0.16722705711921057|       0.2703209879497687|       0.3427559435367584|      0.33015936613082886|       0.3213790241967548|      0.25310173630714417|      0.16979874670505524|      0.23044949769973755|[0.16722705711921...|\n",
      "|    20|        FC Barcelona|      0.43694546818733215|       0.5621862769126892|         0.73206747174263|       0.9132073521614075|      0.39393655955791473|       0.5326567143201828|        0.882788305481275|        0.889985978603363|      0.43694546818733215|      0.29841396808624265|       0.3006210088729858|       0.5154942870140076|       0.2820944720879197|      0.25355029106140137|      0.31524763256311417|       0.3326510526239872|[0.43694546818733...|\n",
      "|    19|          Sevilla FC|       0.1609111037105322|      0.33888248602549237|        0.772539096219199|       0.6061883717775345|       0.6142619468949058|        2.286249428987503|       1.2246057987213135|       0.6634905536969503|      0.16037432104349136|      0.13124597569306692|       0.2758501831974302|      0.32664523646235466|       0.2654028514569456|        2.286249428987503|      0.30607253313064575|      0.25148043036460876|[0.16091110371053...|\n",
      "+------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+--------------------+--------------------+\n",
      "|season|           club_name|avg_dist_macro_role_0_k_2|avg_dist_macro_role_1_k_2|avg_dist_macro_role_2_k_2|avg_dist_macro_role_3_k_2|avg_dist_macro_role_4_k_2|avg_dist_macro_role_5_k_2|avg_dist_macro_role_6_k_2|avg_dist_macro_role_7_k_2|avg_dist_macro_role_0_k_6|avg_dist_macro_role_1_k_6|avg_dist_macro_role_2_k_6|avg_dist_macro_role_3_k_6|avg_dist_macro_role_4_k_6|avg_dist_macro_role_5_k_6|avg_dist_macro_role_6_k_6|avg_dist_macro_role_7_k_6|    avg_dist_vec_k_2|    avg_dist_vec_k_6|\n",
      "+------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+--------------------+--------------------+\n",
      "|    20|         Real Madrid|      0.13310935255140066|       0.6452527642250061|       0.7285355508327485|        1.157500982284546|        0.871081992983818|       0.6796806454658508|       0.8522399167219797|        0.805506432056427|      0.13310935255140066|       0.3338129222393036|       0.4461956024169922|       0.5169087052345276|       0.5049688667058945|      0.27167631685733795|       0.2865249887108803|      0.31541445553302766|[0.13310935255140...|[0.13310935255140...|\n",
      "|    20|     AtlÃ©tico Madrid|       0.2273107667764028|       0.5647262930870056|         1.02837672829628|        2.286249428987503|       0.6670483499765396|        2.286249428987503|        2.286249428987503|       0.6998137633005778|       0.2273107667764028|      0.26262302324175835|       0.3376410812139511|        2.286249428987503|       0.2515212050997294|        2.286249428987503|        2.286249428987503|       0.3298549900452296|[0.22731076677640...|[0.22731076677640...|\n",
      "|    19|           Getafe CF|      0.18396138027310371|       0.4614099085330963|       1.3677110552787781|       0.6238859295845032|      0.39780097348349436|       0.5464516878128052|        2.286249428987503|       0.9184017062187195|      0.17675704658031463|      0.16086379289627076|       0.4240179151296616|       0.5019751638174057|      0.20651001589638845|      0.31192415952682495|        2.286249428987503|      0.47099049389362335|[0.18396138027310...|[0.17675704658031...|\n",
      "|    19|            SD Eibar|      0.16288764029741287|        0.364567032456398|       1.0135307439735957|      0.47893792390823364|       0.6763311454227993|        2.286249428987503|        2.286249428987503|      0.47637004405260086|       0.1623469479382038|       0.2439548283815384|       0.3569730392524174|       0.2937618171175321|      0.42997817269393374|        2.286249428987503|        2.286249428987503|       0.2068634293973446|[0.16288764029741...|[0.16234694793820...|\n",
      "|    19|    Deportivo AlavÃ©s|      0.13154368102550507|      0.46336327493190765|        1.166532650589943|       0.4683908025423686|       0.4906241700053215|        2.286249428987503|        2.286249428987503|       0.7384517431259155|      0.13202214737733206|       0.3028704524040222|      0.25849540407458943|       0.2458489934603373|       0.2584315396845341|        2.286249428987503|        2.286249428987503|       0.3331674292683601|[0.13154368102550...|[0.13202214737733...|\n",
      "|    19|          Levante UD|       0.1188961702088515|       0.2869564912148884|       0.8241235196590424|       0.3450799882411957|       0.6284084071715673|       0.5032863095402718|        2.286249428987503|       0.5266375303268432|      0.11554042001565297|      0.21187701395579747|      0.21011700183153154|      0.26050176844000816|      0.23181475326418877|      0.16162574291229248|        2.286249428987503|      0.20786157995462418|[0.11889617020885...|[0.11554042001565...|\n",
      "|    19|  Real Valladolid CF|      0.23330388218164444|      0.28802480176091194|        0.862929622332255|       0.5669426284730434|       0.5116569929652743|       1.1603126525878906|        2.286249428987503|       0.6940286954243978|      0.22652815779050192|      0.28505128622055054|      0.18898430715004602|      0.17845139279961586|      0.32542509502834743|       0.3774608373641968|        2.286249428987503|      0.31598110993703205|[0.23330388218164...|[0.22652815779050...|\n",
      "|    20|       Real Sociedad|      0.11184458931287129|       0.4659169390797615|       1.1701987147331239|      0.49044619500637054|      0.34400472790002823|       1.0464909374713898|       0.8347765377589634|       0.8519961088895798|      0.11184458931287129|      0.25742589868605137|       0.3410784587264061|       0.1907106339931488|       0.2648012737433116|       0.5558691620826721|       0.3081330380269459|       0.3491248209029436|[0.11184458931287...|[0.11184458931287...|\n",
      "|    19|        RCD Mallorca|       0.2009385128815969|       0.4413555711507797|       0.9887268900871277|        0.292383149266243|       0.5772754574815432|       0.5251393616199493|        2.286249428987503|       0.6172397911548615|      0.19642811516920725|      0.36617109179496765|      0.26823104321956637|        0.199545718729496|      0.28805194546778995|      0.26004649698734283|        2.286249428987503|      0.41362247467041013|[0.20093851288159...|[0.19642811516920...|\n",
      "|    19|       Villarreal CF|      0.16336939732233682|       0.3315502405166626|       0.8774935205777487|       0.2557102342446645|       0.6599699242247475|       0.7699575424194336|        2.286249428987503|       0.6749794960021973|      0.16379109770059586|       0.2134241595864296|        0.293966439863046|      0.17911901324987411|      0.42150263984998065|      0.22500190138816833|        2.286249428987503|      0.18979757130146027|[0.16336939732233...|[0.16379109770059...|\n",
      "|    19|          Real Betis|      0.11722802619139354|      0.41816145181655884|       0.6918608367443084|         0.72795769572258|      0.45196392983198164|       0.8468217551708221|       0.7575444206595421|        0.907449334859848|      0.11061299343903859|      0.18889714032411575|      0.22001413404941558|       0.5118765980005264|      0.31243121698498727|       0.3285170644521713|      0.21867239102721214|       0.3662258982658386|[0.11722802619139...|[0.11061299343903...|\n",
      "|    19|     AtlÃ©tico Madrid|      0.30038780470689136|       0.6275266826152801|       1.0538001507520676|       0.3735186457633972|       0.6170483595795102|        2.286249428987503|       0.9585416913032532|       0.7154351957142353|      0.29936840136845905|      0.25339133441448214|       0.3037826468547185|      0.17898039519786835|      0.22624784211317697|        2.286249428987503|      0.17974579334259033|       0.2673742240294814|[0.30038780470689...|[0.29936840136845...|\n",
      "|    19|          CA Osasuna|       0.1701824553310871|       0.5015701092779636|       0.8444112360477447|      0.33172838389873505|       0.3829645197838545|       0.4593929648399353|        2.286249428987503|       0.5629642128944397|      0.17230880819261074|      0.28198354318737984|       0.3513019621372223|      0.17647884289423624|      0.17892803996801376|       0.2872597575187683|        2.286249428987503|       0.1852712631225586|[0.17018245533108...|[0.17230880819261...|\n",
      "|    20|    Deportivo AlavÃ©s|      0.13139229826629162|       0.6201390794345311|       1.0954987049102782|        2.286249428987503|       0.4611586630344391|        2.286249428987503|        2.286249428987503|       0.6024654731154442|      0.13139229826629162|       0.3922693920986993|      0.31999213099479673|        2.286249428987503|       0.2582198745356156|        2.286249428987503|        2.286249428987503|        0.346450287848711|[0.13139229826629...|[0.13139229826629...|\n",
      "|    20|          Sevilla FC|      0.13481800071895123|       0.6757308294375738|       0.7631292939186096|       0.5491022244095802|      0.48850564445768085|      0.44674524664878845|       1.0879677931467693|       0.6261876374483109|      0.13481800071895123|        0.372043843070666|       0.3296275921165943|      0.21997222304344177|        0.308693921991757|      0.25369784235954285|       0.5105850696563721|       0.3762353528290987|[0.13481800071895...|[0.13481800071895...|\n",
      "|    20|          Real Betis|        0.223610083758831|      0.45808588713407516|       0.5135776698589325|       0.5692213773727417|      0.40295011632972294|       0.9212265014648438|       0.5270781417687734|       0.7187129497528076|        0.223610083758831|       0.2410015407949686|      0.23169560357928276|       0.3197457268834114|      0.21925564441415998|       0.2879308760166168|       0.2698853611946106|      0.34451334178447723|[0.22361008375883...|[0.22361008375883...|\n",
      "|    19|Athletic Club de ...|       0.1410832405090332|       0.4622919838875532|       0.9287812486290932|        2.286249428987503|       0.5885321032255888|        0.837454617023468|       0.4574582725763321|       0.6922027230262756|      0.14165501203387976|      0.27476092241704464|      0.23541311919689178|        2.286249428987503|       0.3994348496198654|       0.5181042104959488|      0.34880536794662476|      0.43517429530620577|[0.14108324050903...|[0.14165501203387...|\n",
      "|    20|           SD Huesca|      0.16722705711921057|       0.3624255607525508|       1.0856523911158245|      0.42652782797813416|       0.5261619748039679|      0.22960874438285828|       0.6763884425163269|      0.49396536499261856|      0.16722705711921057|       0.2703209879497687|       0.3427559435367584|      0.33015936613082886|       0.3213790241967548|      0.25310173630714417|      0.16979874670505524|      0.23044949769973755|[0.16722705711921...|[0.16722705711921...|\n",
      "|    20|        FC Barcelona|      0.43694546818733215|       0.5621862769126892|         0.73206747174263|       0.9132073521614075|      0.39393655955791473|       0.5326567143201828|        0.882788305481275|        0.889985978603363|      0.43694546818733215|      0.29841396808624265|       0.3006210088729858|       0.5154942870140076|       0.2820944720879197|      0.25355029106140137|      0.31524763256311417|       0.3326510526239872|[0.43694546818733...|[0.43694546818733...|\n",
      "|    19|          Sevilla FC|       0.1609111037105322|      0.33888248602549237|        0.772539096219199|       0.6061883717775345|       0.6142619468949058|        2.286249428987503|       1.2246057987213135|       0.6634905536969503|      0.16037432104349136|      0.13124597569306692|       0.2758501831974302|      0.32664523646235466|       0.2654028514569456|        2.286249428987503|      0.30607253313064575|      0.25148043036460876|[0.16091110371053...|[0.16037432104349...|\n",
      "+------+--------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in K:\n",
    "\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=avg_distances_dict[k], outputCol=f\"avg_dist_vec_k_{k}\"\n",
    "    )\n",
    "\n",
    "    teams_df = assembler.transform(teams_df)\n",
    "\n",
    "    teams_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering-learning cross evaluation\n",
    "\n",
    "Classic left-right plot, with:\n",
    "Left Y --> elbow result\n",
    "Right Y --> accuracy\n",
    "X axis --> # clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 4: thinking \"Deep\", shallow injecting some priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the prior (RP coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RP impact\n",
    "\n",
    "plot showing that the more the weight of the RP coefficient is increased, the more the accuracy ofc goes up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
