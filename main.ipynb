{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wall of imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inline\n",
    "%matplotlib widget\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "RANDOM_SEED = None\n",
    "\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import json\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "from pyspark_dist_explore import hist\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "from pyspark.ml.stat import Summarizer\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "from pyspark.ml.feature import UnivariateFeatureSelector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import RFE\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "import warnings # supress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/09 11:58:19 WARN Utils: Your hostname, RTX-2070-Rig resolves to a loopback address: 127.0.1.1; using 192.168.1.189 instead (on interface wlp7s0)\n",
      "22/06/09 11:58:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/09 11:58:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/06/09 11:58:20 WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting port 4051.\n"
     ]
    }
   ],
   "source": [
    "conf = (\n",
    "    SparkConf()\n",
    "    .set(\"spark.ui.port\", \"4050\")\n",
    "    .set(\"spark.executor.memory\", \"4G\")\n",
    "    .set(\"spark.driver.memory\", \"20G\")\n",
    "    .set(\"spark.driver.maxResultSize\", \"10G\")\n",
    ")\n",
    "# .set(\"spark.master\", \"spark://192.168.1.189:4050\")\n",
    "\n",
    "\n",
    "# create the context\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading football players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "modern_df = spark.read.csv(\n",
    "    \"data/players_*.csv\", sep=\",\", inferSchema=True, header=True, multiLine=True\n",
    ")\n",
    "\n",
    "legacy_df = spark.read.csv(\n",
    "    \"data/scraped_players_*.csv\", sep=\",\", inferSchema=True, header=True, \n",
    "    multiLine=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing football players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "leagues = [\n",
    "    \"Spain Primera Division\",\n",
    "    \"German 1. Bundesliga\",\n",
    "    \"French Ligue 1\",\n",
    "    \"English Premier League\",\n",
    "    \"Italian Serie A\",\n",
    "    \"Holland Eredivisie\",\n",
    "]\n",
    "\n",
    "seasons_modern = [\"20\", \"19\", \"18\", \"17\", \"16\", \"15\", \"14\"] \n",
    "seasons_legacy = [\"13\", \"12\", \"11\", \"10\", \"09\", \"08\", \"07\"]\n",
    "# seasons_legacy = [  ]\n",
    "seasons = seasons_legacy + seasons_modern\n",
    "\n",
    "# football_teams = [\n",
    "#     row[\"club_name\"] for row in modern_df.select(\n",
    "#         \"club_name\"\n",
    "#     ).distinct().collect()\n",
    "# ]\n",
    "\n",
    "columns = [\n",
    "    \"short_name\",\n",
    "    \"club_name\",\n",
    "    \"league_name\",\n",
    "    \"season\",\n",
    "    \"pace\",\n",
    "    \"shooting\",\n",
    "    \"passing\",\n",
    "    \"dribbling\",\n",
    "    \"defending\",\n",
    "    \"physic\",\n",
    "    \"attacking_crossing\",\n",
    "    \"attacking_finishing\",\n",
    "    \"attacking_heading_accuracy\",\n",
    "    \"attacking_short_passing\",\n",
    "    \"skill_dribbling\",\n",
    "    \"skill_fk_accuracy\",\n",
    "    \"skill_long_passing\",\n",
    "    \"skill_ball_control\",\n",
    "    \"movement_acceleration\",\n",
    "    \"movement_sprint_speed\",\n",
    "    \"movement_reactions\",\n",
    "    \"power_shot_power\",\n",
    "    \"power_stamina\",\n",
    "    \"power_strength\",\n",
    "    \"power_long_shots\",\n",
    "    \"mentality_aggression\",\n",
    "    \"mentality_penalties\",\n",
    "    \"defending_standing_tackle\"\n",
    "]\n",
    "\n",
    "def get_season(url):\n",
    "    url_split = url.split(\"/\")\n",
    "\n",
    "    # -1 to scale FIFA years down, to have compatibility with all_tables_fixed\n",
    "    return str(\n",
    "        (int(url_split[-2 if url_split[-1] == \"\" else -1][0:2]) - 1)\n",
    "    ).zfill(2)\n",
    "\n",
    "\n",
    "get_season_UDF = udf(lambda url: get_season(url), StringType())\n",
    "\n",
    "roles_to_macro_role_UDF = udf(\n",
    "    lambda roles: float(roles_to_macro_roles_dict[roles.split(\",\")[0]]), StringType()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_modern_df = modern_df.dropDuplicates([\"player_url\"])\n",
    "pre_processed_legacy_df = legacy_df.dropDuplicates([\"player_url\"])\n",
    "\n",
    "pre_processed_modern_df = pre_processed_modern_df.na.fill(0)\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.na.fill(0)\n",
    "\n",
    "pre_processed_modern_df = pre_processed_modern_df.withColumn(\n",
    "    \"season\", get_season_UDF(col(\"player_url\"))\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumn(\n",
    "    \"season\", get_season_UDF(col(\"player_url\"))\n",
    ")\n",
    "\n",
    "pre_processed_modern_df = pre_processed_modern_df.where(\n",
    "    (pre_processed_modern_df.league_name.isin(leagues))\n",
    "    &\n",
    "    (pre_processed_modern_df.season.isin(seasons_modern))\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.where(\n",
    "    (pre_processed_legacy_df.league_name.isin(leagues))\n",
    "    &\n",
    "    (pre_processed_legacy_df.season.isin(seasons_legacy))\n",
    ")\n",
    "\n",
    "pre_processed_modern_df = pre_processed_modern_df.select(columns)\n",
    "\n",
    "# TODO use a for loop\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"pas\", \"passing\"\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"dri\", \"dribbling\"\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.drop(col(\"defending\"))\n",
    "\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"def\", \"defending\"\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"phy\", \"physic\"\n",
    ")\n",
    "\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"sho\", \"shooting\"\n",
    ")\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.withColumnRenamed(\n",
    "    \"pac\", \"pace\"\n",
    ")\n",
    "\n",
    "pre_processed_legacy_df = pre_processed_legacy_df.select(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_df = pre_processed_modern_df.unionByName(\n",
    "    pre_processed_legacy_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building football teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_teams_df = pre_processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAYER_FEATURES = [\n",
    "    \"pace\",\n",
    "    \"shooting\",\n",
    "    \"passing\",\n",
    "    \"dribbling\",\n",
    "    \"defending\",\n",
    "    \"physic\",\n",
    "    \"attacking_crossing\",\n",
    "    \"attacking_finishing\",\n",
    "    \"attacking_heading_accuracy\",\n",
    "    \"attacking_short_passing\",\n",
    "    \"skill_dribbling\",\n",
    "    \"skill_fk_accuracy\",\n",
    "    \"skill_long_passing\",\n",
    "    \"skill_ball_control\",\n",
    "    \"movement_acceleration\",\n",
    "    \"movement_sprint_speed\",\n",
    "    \"movement_reactions\",\n",
    "    \"power_shot_power\",\n",
    "    \"power_stamina\",\n",
    "    \"power_strength\",\n",
    "    \"power_long_shots\",\n",
    "    \"mentality_aggression\",\n",
    "    \"mentality_penalties\",\n",
    "    \"defending_standing_tackle\"\n",
    "]\n",
    "\n",
    "PLAYER_FEATURES_AVG = [\n",
    "    \"avg(\" + player_feature + \")\" for player_feature in PLAYER_FEATURES\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_teams_df = football_teams_df.select(\n",
    "    \"season\", \"club_name\", *PLAYER_FEATURES\n",
    ").groupBy(\n",
    "    [\"season\", \"club_name\"]\n",
    ").agg(\n",
    "    { player_feature: \"avg\" for player_feature in PLAYER_FEATURES }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading football teams seasonal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_scores_df = (\n",
    "    spark.read.csv(\n",
    "        \"data/all_tables_fixed_renamed_leagues.csv\",\n",
    "        sep=\",\",\n",
    "        inferSchema=True,\n",
    "        header=True,\n",
    "        multiLine=True,\n",
    "    )\n",
    "    .withColumnRenamed(\"Year\", \"year\")\n",
    "    .withColumnRenamed(\"Team\", \"club_name_abbr\")\n",
    "    .withColumnRenamed(\"P\", \"points\")\n",
    "    .withColumnRenamed(\"Place\", \"place\")\n",
    "    .withColumnRenamed(\"League\", \"league\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing football teams seasonal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_scores_columns = [\n",
    "    \"year\", \"club_name_abbr\", \"points\", \"place\", \"league\"\n",
    "]\n",
    "\n",
    "f = open(\"data/clubs_map.json\")\n",
    "club_name_abbr_to_ext = json.load(f)\n",
    "f.close()\n",
    "\n",
    "abbreviate_season_UDF = udf(\n",
    "    lambda season: str(season)[-2:],\n",
    "    StringType(),\n",
    ")\n",
    "\n",
    "def extend_club_name(club_name_abbr):\n",
    "    try:\n",
    "        return club_name_abbr_to_ext[club_name_abbr]\n",
    "    except KeyError as e:\n",
    "        return \"NOT_FOUND\"\n",
    "    except Exception as e:\n",
    "        return \"GENERAL_EXCEPTION\"\n",
    "\n",
    "extend_club_name_UDF = udf(\n",
    "    lambda club_name_abbr: extend_club_name(str(club_name_abbr)),\n",
    "    StringType(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_seasonal_scores_df = seasonal_scores_df\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.dropDuplicates(\n",
    "    seasonal_scores_columns\n",
    ")\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.na.fill(0)\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.select(\n",
    "    seasonal_scores_columns\n",
    ")\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.withColumn(\n",
    "    \"year\", abbreviate_season_UDF(col(\"year\"))\n",
    ")\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.withColumn(\n",
    "    \"club_name_ext\", extend_club_name_UDF(col(\"club_name_abbr\"))\n",
    ")\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.withColumn(\n",
    "    \"points\", pre_processed_seasonal_scores_df.points.cast(DoubleType())\n",
    ")\n",
    "\n",
    "if pre_processed_seasonal_scores_df.filter(\n",
    "    col(\"club_name_ext\") == \"NOT_FOUND\"\n",
    ").count() > 0:\n",
    "    print(\"WARN: some clubs have NOT been found\")\n",
    "    print(\"Please check your data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.where(\n",
    "    (pre_processed_seasonal_scores_df.year.isin(seasons))\n",
    "    & (pre_processed_seasonal_scores_df.league.isin(leagues))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|  07|\n",
      "|  15|\n",
      "|  11|\n",
      "|  16|\n",
      "|  18|\n",
      "|  17|\n",
      "|  09|\n",
      "|  19|\n",
      "|  08|\n",
      "|  20|\n",
      "|  10|\n",
      "|  12|\n",
      "|  13|\n",
      "|  14|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_processed_seasonal_scores_df.select(\"year\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_scores_pre_join_columns = [\n",
    "    \"year\", \"league\", \"club_name_ext\", \"points\", \"place\"\n",
    "]\n",
    "\n",
    "pre_processed_seasonal_scores_df = pre_processed_seasonal_scores_df.select(\n",
    "    seasonal_scores_pre_join_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining football teams features with their seasonal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = football_teams_df.join(\n",
    "    pre_processed_seasonal_scores_df,\n",
    "    (football_teams_df.season == pre_processed_seasonal_scores_df.year)\n",
    "    & (\n",
    "        football_teams_df.club_name\n",
    "        == pre_processed_seasonal_scores_df.club_name_ext\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:======================================>                 (19 + 9) / 28]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Some football teams have been left out the join (football_teams_df)\n",
      "Please, check your data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if pre_processed_seasonal_scores_df.select(\"club_name_ext\").distinct().subtract(\n",
    "    df.select(\"club_name_ext\").distinct()\n",
    ").count() > 0:\n",
    "    print(\"WARN: Some football teams have been left out the join (pre_processed_seasonal_scores_df)\")\n",
    "    print(\"Please, check your data!\")\n",
    "\n",
    "if football_teams_df.select(\"club_name\").distinct().subtract(\n",
    "    df.select(\"club_name_ext\").distinct()\n",
    ").count() > 0:\n",
    "    print(\"WARN: Some football teams have been left out the join (football_teams_df)\")\n",
    "    print(\"Please, check your data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|club_name                |\n",
      "+-------------------------+\n",
      "|SC Bastia                |\n",
      "|RCD Espanyol de Barcelona|\n",
      "|F.C. Hansa Rostock       |\n",
      "|Unión Deportiva Almería  |\n",
      "|Sport-Club Freiburg      |\n",
      "|Real Betis Balompié      |\n",
      "|TSG Hoffenheim           |\n",
      "|N.E.C. Nijmegen          |\n",
      "|Levante Unión Deportiva  |\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "football_teams_df.select(\"club_name\").distinct().subtract(\n",
    "    df.select(\"club_name_ext\").distinct()\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
